{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import twitter_samples\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "import collections\n",
    "from argparse import Namespace\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/lifeonthefence/text-success/main/Data/Ukraine%20Tweets.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset = 'id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precounting of features: Length, Hashtags, URLs and Mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet_length'] = df['rendered_content'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_mentions'] = df['rendered_content'].apply(lambda x: x.count('@'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_hashtags'] = df['rendered_content'].apply(lambda x: x.count('#'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_urls'] = df['rendered_content'].apply(lambda x: x.count('https'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps taken:\n",
    "- Converting emojis to text\n",
    "- We decide to remove all the mentions and hashtagged words, as these will be analysed separately\n",
    "- Remove Links, as these don't contribute to SA\n",
    "- Conducting the SA on our preprocessed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a new column so that we can see the adjusted tweet and original versiom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(loc=6,\n",
    "          column='Adjusted Tweet',\n",
    "          value=df['rendered_content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting emojis to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "\n",
    "def demote(text):\n",
    "    text = emoji.demojize(text)\n",
    "    return text\n",
    "\n",
    "df['Adjusted Tweet'] = df['Adjusted Tweet'].apply(demote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing mentions and hashtagged words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_mentions_hashtags(text):\n",
    "    text = re.sub(\"@[A-Za-z0-9_]+\",\"\", text)\n",
    "    text = re.sub(\"#[A-Za-z0-9_]+\",\"\", text)\n",
    "    return text\n",
    "\n",
    "df['Adjusted Tweet'] = df['Adjusted Tweet'].apply(remove_mentions_hashtags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_links(text):\n",
    "    text = re.sub('http://\\S+|https://\\S+', '', text)\n",
    "    text = re.sub('http[s]?://\\S+', '', text)\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    text = re.sub(r'bit.ly/\\S+', '', text) # remove bitly links\n",
    "    text = text.strip('[link]') # remove [links]\n",
    "    return text\n",
    "\n",
    "df['Adjusted Tweet'] = df['Adjusted Tweet'].apply(remove_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/zofiachoinska/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/zofiachoinska/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zofiachoinska/opt/anaconda3/lib/python3.9/runpy.py:127: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/zofiachoinska/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "\n",
    "SENT_DETECTOR = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "! python -m nltk.downloader punkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: NLP-python in ./opt/anaconda3/lib/python3.9/site-packages (1.1.0)\n",
      "Requirement already satisfied: numpy in ./opt/anaconda3/lib/python3.9/site-packages (from NLP-python) (1.21.5)\n",
      "Requirement already satisfied: scikit-learn in ./opt/anaconda3/lib/python3.9/site-packages (from NLP-python) (1.0.2)\n",
      "Requirement already satisfied: pandas in ./opt/anaconda3/lib/python3.9/site-packages (from NLP-python) (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in ./opt/anaconda3/lib/python3.9/site-packages (from pandas->NLP-python) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./opt/anaconda3/lib/python3.9/site-packages (from pandas->NLP-python) (2022.1)\n",
      "Requirement already satisfied: joblib>=0.11 in ./opt/anaconda3/lib/python3.9/site-packages (from scikit-learn->NLP-python) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in ./opt/anaconda3/lib/python3.9/site-packages (from scikit-learn->NLP-python) (1.9.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./opt/anaconda3/lib/python3.9/site-packages (from scikit-learn->NLP-python) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in ./opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->NLP-python) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install NLP-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fk/81vm3qzx55z_4v1mpq7r9xm40000gn/T/ipykernel_93312/2530010690.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Adjusted Tweet'] = df['Adjusted Tweet'].str.replace('\\d+', '')\n"
     ]
    }
   ],
   "source": [
    "df['Adjusted Tweet'] = df['Adjusted Tweet'].str.replace('\\d+', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing Non-English Characters, Accents and Remaining Punctuation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fk/81vm3qzx55z_4v1mpq7r9xm40000gn/T/ipykernel_93312/1443758219.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Adjusted Tweet'] = df['Adjusted Tweet'].str.replace(r'[^\\x00-\\x7F]+', '')\n"
     ]
    }
   ],
   "source": [
    "df['Adjusted Tweet'] = df['Adjusted Tweet'].str.replace(r'[^\\x00-\\x7F]+', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert Polarity Score Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(loc=7,\n",
    "          column='Polarity Score',\n",
    "          value=df['Adjusted Tweet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment Analysis using NLTK's VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Uncomment to download lexicon for the first time \n",
    "#import nltk\n",
    "#nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/zofiachoinska/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def sentiment_analysis(text):  \n",
    "    text = sia.polarity_scores(text)\n",
    "    return text\n",
    "\n",
    "df['Polarity Score'] = df['Polarity Score'].apply(sentiment_analysis)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating columns for:\n",
    "- Negative Score\n",
    "- Neutral Score\n",
    "- Positive Score\n",
    "- Compound Score [-1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(loc=8,\n",
    "          column='Negative Score',\n",
    "          value=df['Polarity Score'])\n",
    "\n",
    "df.insert(loc=9,\n",
    "          column='Neutral Score',\n",
    "          value=df['Polarity Score'])\n",
    "\n",
    "df.insert(loc=10,\n",
    "          column='Positive Score',\n",
    "          value=df['Polarity Score'])\n",
    "\n",
    "df.insert(loc=11,\n",
    "          column='Compound Score',\n",
    "          value=df['Polarity Score'])\n",
    "\n",
    "df['Negative Score'] = df['Negative Score'].apply(lambda x: x['neg'])\n",
    "df['Neutral Score'] = df['Neutral Score'].apply(lambda x: x['neu'])\n",
    "df['Positive Score'] = df['Positive Score'].apply(lambda x: x['pos'])\n",
    "df['Compound Score'] = df['Compound Score'].apply(lambda x: x['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>user</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>user_created</th>\n",
       "      <th>rendered_content</th>\n",
       "      <th>Adjusted Tweet</th>\n",
       "      <th>Polarity Score</th>\n",
       "      <th>Negative Score</th>\n",
       "      <th>Neutral Score</th>\n",
       "      <th>...</th>\n",
       "      <th>replies</th>\n",
       "      <th>quoteCount</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>lang</th>\n",
       "      <th>media</th>\n",
       "      <th>mentionedUsers</th>\n",
       "      <th>tweet_length</th>\n",
       "      <th>num_mentions</th>\n",
       "      <th>num_hashtags</th>\n",
       "      <th>num_urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1477420789863436289</td>\n",
       "      <td>2022-01-01 23:25:40+00:00</td>\n",
       "      <td>anno1540</td>\n",
       "      <td>8838</td>\n",
       "      <td>2014-06-12 17:05:22+00:00</td>\n",
       "      <td>Lithuania will never abandon Ukraine, voluntee...</td>\n",
       "      <td>Lithuania will never abandon Ukraine, voluntee...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.661, 'pos': 0.339, 'comp...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.661</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['Lithuania', 'Ukraine']</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1477414596424220679</td>\n",
       "      <td>2022-01-01 23:01:03+00:00</td>\n",
       "      <td>weather_odessa</td>\n",
       "      <td>119</td>\n",
       "      <td>2019-07-10 08:34:22+00:00</td>\n",
       "      <td>#odessa #odesa #ukraine #–æ–¥–µ—Å—Å–∞\\nNow: 4.2¬∞C\\nT...</td>\n",
       "      <td>#\\nNow: .C\\nToday's Min: .C at ::\\nToday's ...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['odessa', 'odesa', 'ukraine', '–æ–¥–µ—Å—Å–∞']</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1477414332376010752</td>\n",
       "      <td>2022-01-01 23:00:00+00:00</td>\n",
       "      <td>AlArabiya_Eng</td>\n",
       "      <td>927174</td>\n",
       "      <td>2009-02-28 08:31:32+00:00</td>\n",
       "      <td>After tough talk between Presidents Joe Biden ...</td>\n",
       "      <td>After tough talk between Presidents Joe Biden ...</td>\n",
       "      <td>{'neg': 0.099, 'neu': 0.776, 'pos': 0.125, 'co...</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.776</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>['Russia', 'Ukraine']</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>277</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1477409748572151809</td>\n",
       "      <td>2022-01-01 22:41:47+00:00</td>\n",
       "      <td>beatravelling</td>\n",
       "      <td>6329</td>\n",
       "      <td>2014-02-28 21:25:33+00:00</td>\n",
       "      <td>The beach can be nice in the fall too üòäüá∫üá¶\\n\\n#...</td>\n",
       "      <td>The beach can be nice in the fall too :smiling...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.781, 'pos': 0.219, 'comp...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.781</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['lanzheron', 'langeron', 'beach', 'odessa', '...</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1477409332820119552</td>\n",
       "      <td>2022-01-01 22:40:08+00:00</td>\n",
       "      <td>TornCurtain1991</td>\n",
       "      <td>677</td>\n",
       "      <td>2012-02-08 15:30:41+00:00</td>\n",
       "      <td>A note: Stepan #Bandera, DOB 01011909, was lea...</td>\n",
       "      <td>A note: Stepan , DOB , was leader of Organizat...</td>\n",
       "      <td>{'neg': 0.18, 'neu': 0.82, 'pos': 0.0, 'compou...</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.820</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['Bandera', 'Ukraine']</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>278</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                       date             user  \\\n",
       "0  1477420789863436289  2022-01-01 23:25:40+00:00         anno1540   \n",
       "1  1477414596424220679  2022-01-01 23:01:03+00:00   weather_odessa   \n",
       "2  1477414332376010752  2022-01-01 23:00:00+00:00    AlArabiya_Eng   \n",
       "3  1477409748572151809  2022-01-01 22:41:47+00:00    beatravelling   \n",
       "4  1477409332820119552  2022-01-01 22:40:08+00:00  TornCurtain1991   \n",
       "\n",
       "   user_followers               user_created  \\\n",
       "0            8838  2014-06-12 17:05:22+00:00   \n",
       "1             119  2019-07-10 08:34:22+00:00   \n",
       "2          927174  2009-02-28 08:31:32+00:00   \n",
       "3            6329  2014-02-28 21:25:33+00:00   \n",
       "4             677  2012-02-08 15:30:41+00:00   \n",
       "\n",
       "                                    rendered_content  \\\n",
       "0  Lithuania will never abandon Ukraine, voluntee...   \n",
       "1  #odessa #odesa #ukraine #–æ–¥–µ—Å—Å–∞\\nNow: 4.2¬∞C\\nT...   \n",
       "2  After tough talk between Presidents Joe Biden ...   \n",
       "3  The beach can be nice in the fall too üòäüá∫üá¶\\n\\n#...   \n",
       "4  A note: Stepan #Bandera, DOB 01011909, was lea...   \n",
       "\n",
       "                                      Adjusted Tweet  \\\n",
       "0  Lithuania will never abandon Ukraine, voluntee...   \n",
       "1     #\\nNow: .C\\nToday's Min: .C at ::\\nToday's ...   \n",
       "2  After tough talk between Presidents Joe Biden ...   \n",
       "3  The beach can be nice in the fall too :smiling...   \n",
       "4  A note: Stepan , DOB , was leader of Organizat...   \n",
       "\n",
       "                                      Polarity Score  Negative Score  \\\n",
       "0  {'neg': 0.0, 'neu': 0.661, 'pos': 0.339, 'comp...           0.000   \n",
       "1  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...           0.000   \n",
       "2  {'neg': 0.099, 'neu': 0.776, 'pos': 0.125, 'co...           0.099   \n",
       "3  {'neg': 0.0, 'neu': 0.781, 'pos': 0.219, 'comp...           0.000   \n",
       "4  {'neg': 0.18, 'neu': 0.82, 'pos': 0.0, 'compou...           0.180   \n",
       "\n",
       "   Neutral Score  ...  replies  quoteCount  \\\n",
       "0          0.661  ...        0           0   \n",
       "1          1.000  ...        0           0   \n",
       "2          0.776  ...        3           0   \n",
       "3          0.781  ...        0           0   \n",
       "4          0.820  ...        0           0   \n",
       "\n",
       "                                            hashtags  lang  media  \\\n",
       "0                           ['Lithuania', 'Ukraine']    en    NaN   \n",
       "1           ['odessa', 'odesa', 'ukraine', '–æ–¥–µ—Å—Å–∞']    en    NaN   \n",
       "2                              ['Russia', 'Ukraine']    en    NaN   \n",
       "3  ['lanzheron', 'langeron', 'beach', 'odessa', '...    en    NaN   \n",
       "4                             ['Bandera', 'Ukraine']    en    NaN   \n",
       "\n",
       "   mentionedUsers tweet_length num_mentions num_hashtags num_urls  \n",
       "0             NaN          132            0            2        0  \n",
       "1             NaN          188            0            4        0  \n",
       "2             NaN          277            0            2        0  \n",
       "3             NaN          122            0            5        0  \n",
       "4             NaN          278            0            2        0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(loc=12,\n",
    "          column='Polarity Score_textblob',\n",
    "          value=df['Adjusted Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(loc=13,\n",
    "          column='Subjectivity Score_textblob',\n",
    "          value=df['Adjusted Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in ./opt/anaconda3/lib/python3.9/site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in ./opt/anaconda3/lib/python3.9/site-packages (from textblob) (3.7)\n",
      "Requirement already satisfied: joblib in ./opt/anaconda3/lib/python3.9/site-packages (from nltk>=3.1->textblob) (1.1.0)\n",
      "Requirement already satisfied: click in ./opt/anaconda3/lib/python3.9/site-packages (from nltk>=3.1->textblob) (8.0.4)\n",
      "Requirement already satisfied: tqdm in ./opt/anaconda3/lib/python3.9/site-packages (from nltk>=3.1->textblob) (4.64.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./opt/anaconda3/lib/python3.9/site-packages (from nltk>=3.1->textblob) (2022.7.9)\n",
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     /Users/zofiachoinska/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/zofiachoinska/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/zofiachoinska/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/zofiachoinska/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package conll2000 to\n",
      "[nltk_data]     /Users/zofiachoinska/nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /Users/zofiachoinska/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "! pip install -U textblob\n",
    "! python -m textblob.download_corpora\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "#Create a function to get the subjectivity\n",
    "def getSubjectivity(text):\n",
    "    return TextBlob(text).sentiment.subjectivity\n",
    "\n",
    "#Create a function to get the polarity\n",
    "def getPolarity(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "df['Polarity Score_textblob'] = df['Polarity Score_textblob'].apply(getPolarity)\n",
    "df['Subjectivity Score_textblob'] = df['Subjectivity Score_textblob'].apply(getSubjectivity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further manipulating the tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps taken:\n",
    "- Lowercase\n",
    "- Punctuation\n",
    "- Tokenization\n",
    "- Stopword filtering\n",
    "- Lemmatisation\n",
    "- Number removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing all text to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Adjusted Tweet'] = df['Adjusted Tweet'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing all Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def punctuation_remove(text):\n",
    "    text = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    return text\n",
    "\n",
    "df['Adjusted Tweet'] = df['Adjusted Tweet'].apply(punctuation_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_numbers(text):\n",
    "    no_numbers = re.sub(r'\\d+', '', text)\n",
    "    return no_numbers\n",
    "\n",
    "df['Adjusted Tweet'] = df['Adjusted Tweet'].apply(remove_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "def tokenize(text):\n",
    "    text = word_tokenize(text)\n",
    "    return text\n",
    "\n",
    "df['Adjusted Tweet'] = df['Adjusted Tweet'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopword Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/zofiachoinska/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "    \n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stop_words = stopwords.words('english')\n",
    "    text = [word for word in text if word not in stop_words]\n",
    "    return text\n",
    "\n",
    "df['Adjusted Tweet'] = df['Adjusted Tweet'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/zofiachoinska/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('omw-1.4')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "def lemmatise(text): \n",
    "    lemma = [wnl.lemmatize(word) for word in text]\n",
    "    return lemma\n",
    "\n",
    "df['Adjusted Tweet'] = df['Adjusted Tweet'].apply(lemmatise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Months since creation of account relative to tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding date of account creation in months\n",
    "df.insert(loc=5,\n",
    "          column='Date of Creation in months',\n",
    "          value=df['user_created'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import *\n",
    "\n",
    "#returning the months of account creation\n",
    "def account_creation(text):\n",
    "    text = datetime.strptime(text, \"%Y-%m-%d %H:%M:%S+00:00\")\n",
    "    year = str(text)[0:4]\n",
    "    month = str(text)[5:7]\n",
    "    total_months = (int(year)*12)+(int(month))\n",
    "    return (total_months)\n",
    "\n",
    "df['Date of Creation in months'] = df['Date of Creation in months'].apply(account_creation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding date of tweet in months\n",
    "df.insert(loc=6,\n",
    "          column='Date of Tweet in Months',\n",
    "          value=df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return the year of tweet\n",
    "df['Date of Tweet in Months'] = df['Date of Tweet in Months'].apply(account_creation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating Months since creation of account relative to tweet\n",
    "df.insert(loc=7,\n",
    "          column='Months Since Creation of Account',\n",
    "          value= (df['Date of Tweet in Months']-df['Date of Creation in months']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time of Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a column for hours:\n",
    "df.insert(loc=2,\n",
    "          column='hour of tweet',\n",
    "          value=df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "#return the hour of the tweet\n",
    "def hour(text):\n",
    "    text = datetime.strptime(text, \"%Y-%m-%d %H:%M:%S+00:00\")\n",
    "    hour = str(text.time())[0:2]\n",
    "    return int(hour)\n",
    "\n",
    "df['hour of tweet'] = df['hour of tweet'].apply(hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert column for the time of day\n",
    "df.insert(loc=3,\n",
    "          column='time of day',\n",
    "          value=df['hour of tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the time of day\n",
    "def time_of_day(text):  \n",
    "    if ((text > 4) and (text < 8 )):\n",
    "        return 'Early Morning'\n",
    "    elif ((text > 8) and (text < 12 )):\n",
    "        return 'Morning'\n",
    "    elif ((text > 12) and (text < 16 )):\n",
    "        return 'Noon'\n",
    "    elif ((text > 16) and (text < 20 )):\n",
    "        return 'Eve'\n",
    "    elif ((text > 20) and (text < 24 )):\n",
    "        return 'Night'\n",
    "    elif ((text > 0) and (text < 4 )):\n",
    "        return 'Late Night'\n",
    "    \n",
    "df['time of day'] = df['time of day'].apply(time_of_day)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating counts using one hot encoding\n",
    "\n",
    "#Early Morning Count\n",
    "df.insert(loc=4,\n",
    "          column='Early Morning Count',\n",
    "          value=df['time of day'])\n",
    "\n",
    "def early_morning_count(text):\n",
    "    if text == 'Early Morning':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df['Early Morning Count'] = df['Early Morning Count'].apply(early_morning_count)\n",
    "\n",
    "#Morning Count\n",
    "df.insert(loc=5,\n",
    "          column='Morning Count',\n",
    "          value=df['time of day'])\n",
    "\n",
    "def morning_count(text):\n",
    "    if text == 'Morning':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df['Morning Count'] = df['Morning Count'].apply(morning_count)\n",
    "\n",
    "#Noon count\n",
    "df.insert(loc=6,\n",
    "          column='Noon Count',\n",
    "          value=df['time of day'])\n",
    "\n",
    "def noon_count(text):\n",
    "    if text == 'Noon':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df['Noon Count'] = df['Noon Count'].apply(noon_count)\n",
    "\n",
    "#Eve count\n",
    "df.insert(loc=7,\n",
    "          column='Eve Count',\n",
    "          value=df['time of day'])\n",
    "\n",
    "def eve_count(text):\n",
    "    if text == 'Eve':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df['Eve Count'] = df['Eve Count'].apply(eve_count)\n",
    "\n",
    "#Night count\n",
    "df.insert(loc=8,\n",
    "          column='Night Count',\n",
    "          value=df['time of day'])\n",
    "\n",
    "def night_count(text):\n",
    "    if text == 'Night':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df['Night Count'] = df['Night Count'].apply(night_count)\n",
    "\n",
    "#Late Night count\n",
    "df.insert(loc=9,\n",
    "          column='Late Night Count',\n",
    "          value=df['time of day'])\n",
    "\n",
    "def late_night_count(text):\n",
    "    if text == 'Late Night':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df['Late Night Count'] = df['Late Night Count'].apply(late_night_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video, GIF and Photo Count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Photo Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a photo count column...\n",
    "df.insert(loc=23,\n",
    "          column='Photo Count',\n",
    "          value=df['media'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counting number of Photos in media column\n",
    "#No need to tokenize\n",
    "def photo_count(text):\n",
    "    text = str(text)\n",
    "    text = text.count('Photo')\n",
    "    return text\n",
    "\n",
    "df['Photo Count'] = df['Photo Count'].apply(photo_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Video Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a video count column...\n",
    "df.insert(loc=24,\n",
    "          column='Video Count',\n",
    "          value=df['media'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need to tokenize the media column so that we can count how many videos there are...\n",
    "from nltk import word_tokenize\n",
    "\n",
    "def tokenize(text):\n",
    "    text = str(text)\n",
    "    text = word_tokenize(text)\n",
    "    return text\n",
    "\n",
    "df['Video Count'] = df['Video Count'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counting number of Videos in media column\n",
    "def video_count(text):\n",
    "    text = text.count('Video')\n",
    "    return text\n",
    "\n",
    "df['Video Count'] = df['Video Count'].apply(video_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gif Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a GIF count column...\n",
    "df.insert(loc=25,\n",
    "          column='GIF Count',\n",
    "          value=df['media'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need to tokenize the media column so that we can count how many GIFs there are...\n",
    "from nltk import word_tokenize\n",
    "\n",
    "def tokenize(text):\n",
    "    text = str(text)\n",
    "    text = word_tokenize(text)\n",
    "    return text\n",
    "\n",
    "df['GIF Count'] = df['GIF Count'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counting number of GIFs in media column\n",
    "def gif_count(text):\n",
    "    text = text.count('Gif')\n",
    "    return text\n",
    "\n",
    "df['GIF Count'] = df['GIF Count'].apply(gif_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [lithuania, never, abandon, ukraine, volunteer...\n",
       "1        [c, today, min, c, today, max, c, month, min, ...\n",
       "2        [tough, talk, president, joe, biden, vladimir,...\n",
       "3        [beach, nice, fall, smilingfacewithsmilingeyes...\n",
       "4        [note, stepan, dob, leader, organization, ukra...\n",
       "                               ...                        \n",
       "60128    [announces, strengthen, armed, happened, ukrai...\n",
       "60129    [living, govt, bomb, neighbouring, country, st...\n",
       "60130    [alexander, mercouri, comment, ray, mcgoverns,...\n",
       "60131    [nice, overview, capability, bradley, ifvs, ma...\n",
       "60132    [vasyl, malyuk, head, sbu, secret, police, say...\n",
       "Name: Adjusted Tweet, Length: 57862, dtype: object"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Adjusted Tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zofiachoinska/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def dummy(x):\n",
    "    return x\n",
    "\n",
    "vectorizer = CountVectorizer(max_df = 0.9, min_df = 25, lowercase = False, tokenizer = dummy)\n",
    "tf = vectorizer.fit_transform(df['Adjusted Tweet']).toarray()\n",
    "tf_features_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "number_of_topics = 3\n",
    "\n",
    "model = LatentDirichletAllocation(n_components=number_of_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(n_components=3)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    topic_dict = {}\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        topic_dict[\"Topic %d words\" % (topic_idx)]= ['{}'.format(feature_names[i])\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]\n",
    "        topic_dict[\"Topic %d weights\" % (topic_idx)]= ['{:.1f}'.format(topic[i])\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]\n",
    "    return pd.DataFrame(topic_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 0 words</th>\n",
       "      <th>Topic 0 weights</th>\n",
       "      <th>Topic 1 words</th>\n",
       "      <th>Topic 1 weights</th>\n",
       "      <th>Topic 2 words</th>\n",
       "      <th>Topic 2 weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ukraine</td>\n",
       "      <td>4874.3</td>\n",
       "      <td>ukraine</td>\n",
       "      <td>5368.5</td>\n",
       "      <td>russian</td>\n",
       "      <td>6692.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>war</td>\n",
       "      <td>4554.9</td>\n",
       "      <td>russia</td>\n",
       "      <td>3445.4</td>\n",
       "      <td>ukrainian</td>\n",
       "      <td>4481.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amp</td>\n",
       "      <td>3651.4</td>\n",
       "      <td>russian</td>\n",
       "      <td>2597.3</td>\n",
       "      <td>ukraine</td>\n",
       "      <td>4230.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u</td>\n",
       "      <td>3331.4</td>\n",
       "      <td>missile</td>\n",
       "      <td>1913.0</td>\n",
       "      <td>force</td>\n",
       "      <td>3588.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>people</td>\n",
       "      <td>2948.1</td>\n",
       "      <td>military</td>\n",
       "      <td>1476.6</td>\n",
       "      <td>war</td>\n",
       "      <td>1896.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>russia</td>\n",
       "      <td>2383.4</td>\n",
       "      <td>u</td>\n",
       "      <td>1377.5</td>\n",
       "      <td>putin</td>\n",
       "      <td>1776.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>help</td>\n",
       "      <td>1836.7</td>\n",
       "      <td>attack</td>\n",
       "      <td>1211.1</td>\n",
       "      <td>soldier</td>\n",
       "      <td>1736.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>world</td>\n",
       "      <td>1779.2</td>\n",
       "      <td>war</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>troop</td>\n",
       "      <td>1461.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>like</td>\n",
       "      <td>1532.0</td>\n",
       "      <td>news</td>\n",
       "      <td>1093.3</td>\n",
       "      <td>russia</td>\n",
       "      <td>1376.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>support</td>\n",
       "      <td>1463.1</td>\n",
       "      <td>via</td>\n",
       "      <td>1048.1</td>\n",
       "      <td>region</td>\n",
       "      <td>1304.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Topic 0 words Topic 0 weights Topic 1 words Topic 1 weights Topic 2 words  \\\n",
       "0       ukraine          4874.3       ukraine          5368.5       russian   \n",
       "1           war          4554.9        russia          3445.4     ukrainian   \n",
       "2           amp          3651.4       russian          2597.3       ukraine   \n",
       "3             u          3331.4       missile          1913.0         force   \n",
       "4        people          2948.1      military          1476.6           war   \n",
       "5        russia          2383.4             u          1377.5         putin   \n",
       "6          help          1836.7        attack          1211.1       soldier   \n",
       "7         world          1779.2           war          1138.0         troop   \n",
       "8          like          1532.0          news          1093.3        russia   \n",
       "9       support          1463.1           via          1048.1        region   \n",
       "\n",
       "  Topic 2 weights  \n",
       "0          6692.7  \n",
       "1          4481.3  \n",
       "2          4230.2  \n",
       "3          3588.8  \n",
       "4          1896.1  \n",
       "5          1776.9  \n",
       "6          1736.4  \n",
       "7          1461.3  \n",
       "8          1376.2  \n",
       "9          1304.9  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_top_words = 10\n",
    "display_topics(model, tf_features_names, no_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zofiachoinska/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_nmf.py:1422: FutureWarning: `alpha` was deprecated in version 1.0 and will be removed in 1.2. Use `alpha_W` and `alpha_H` instead\n",
      "  warnings.warn(\n",
      "/Users/zofiachoinska/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n",
      "/Users/zofiachoinska/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_nmf.py:1637: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.1, l1_ratio=0.5, n_components=4, random_state=0)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "model_2 = NMF(n_components=4, random_state=0, alpha=.1, l1_ratio=.5)\n",
    "\n",
    "model_2.fit(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 0 words</th>\n",
       "      <th>Topic 0 weights</th>\n",
       "      <th>Topic 1 words</th>\n",
       "      <th>Topic 1 weights</th>\n",
       "      <th>Topic 2 words</th>\n",
       "      <th>Topic 2 weights</th>\n",
       "      <th>Topic 3 words</th>\n",
       "      <th>Topic 3 weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ukraine</td>\n",
       "      <td>18.7</td>\n",
       "      <td>russian</td>\n",
       "      <td>15.0</td>\n",
       "      <td>war</td>\n",
       "      <td>15.7</td>\n",
       "      <td>russia</td>\n",
       "      <td>13.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u</td>\n",
       "      <td>1.6</td>\n",
       "      <td>ukrainian</td>\n",
       "      <td>5.9</td>\n",
       "      <td>putin</td>\n",
       "      <td>1.4</td>\n",
       "      <td>amp</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>help</td>\n",
       "      <td>1.4</td>\n",
       "      <td>force</td>\n",
       "      <td>3.4</td>\n",
       "      <td>world</td>\n",
       "      <td>1.0</td>\n",
       "      <td>u</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>people</td>\n",
       "      <td>1.3</td>\n",
       "      <td>soldier</td>\n",
       "      <td>1.4</td>\n",
       "      <td>news</td>\n",
       "      <td>0.9</td>\n",
       "      <td>putin</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>please</td>\n",
       "      <td>1.1</td>\n",
       "      <td>military</td>\n",
       "      <td>1.4</td>\n",
       "      <td>end</td>\n",
       "      <td>0.8</td>\n",
       "      <td>military</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>link</td>\n",
       "      <td>1.1</td>\n",
       "      <td>troop</td>\n",
       "      <td>1.2</td>\n",
       "      <td>crime</td>\n",
       "      <td>0.8</td>\n",
       "      <td>country</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>follow</td>\n",
       "      <td>1.0</td>\n",
       "      <td>missile</td>\n",
       "      <td>1.1</td>\n",
       "      <td>one</td>\n",
       "      <td>0.6</td>\n",
       "      <td>say</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>article</td>\n",
       "      <td>1.0</td>\n",
       "      <td>region</td>\n",
       "      <td>1.1</td>\n",
       "      <td>video</td>\n",
       "      <td>0.6</td>\n",
       "      <td>people</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>force</td>\n",
       "      <td>0.8</td>\n",
       "      <td>army</td>\n",
       "      <td>1.0</td>\n",
       "      <td>day</td>\n",
       "      <td>0.5</td>\n",
       "      <td>world</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>day</td>\n",
       "      <td>0.7</td>\n",
       "      <td>attack</td>\n",
       "      <td>1.0</td>\n",
       "      <td>stop</td>\n",
       "      <td>0.5</td>\n",
       "      <td>weapon</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Topic 0 words Topic 0 weights Topic 1 words Topic 1 weights Topic 2 words  \\\n",
       "0       ukraine            18.7       russian            15.0           war   \n",
       "1             u             1.6     ukrainian             5.9         putin   \n",
       "2          help             1.4         force             3.4         world   \n",
       "3        people             1.3       soldier             1.4          news   \n",
       "4        please             1.1      military             1.4           end   \n",
       "5          link             1.1         troop             1.2         crime   \n",
       "6        follow             1.0       missile             1.1           one   \n",
       "7       article             1.0        region             1.1         video   \n",
       "8         force             0.8          army             1.0           day   \n",
       "9           day             0.7        attack             1.0          stop   \n",
       "\n",
       "  Topic 2 weights Topic 3 words Topic 3 weights  \n",
       "0            15.7        russia            13.2  \n",
       "1             1.4           amp             7.6  \n",
       "2             1.0             u             3.9  \n",
       "3             0.9         putin             1.7  \n",
       "4             0.8      military             1.2  \n",
       "5             0.8       country             1.2  \n",
       "6             0.6           say             1.1  \n",
       "7             0.6        people             1.1  \n",
       "8             0.5         world             1.1  \n",
       "9             0.5        weapon             0.8  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_topics(model_2, tf_features_names, no_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like these clustering algorithms do not pick up any interesting clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = df['Adjusted Tweet'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zofiachoinska/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "def dummy(x):\n",
    "    return x\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df = 0.9, min_df = 50, lowercase = False, tokenizer = dummy)\n",
    "tf = vectorizer.fit_transform(df['Adjusted Tweet']).toarray()\n",
    "tf_features_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abandoned</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>accept</th>\n",
       "      <th>access</th>\n",
       "      <th>accident</th>\n",
       "      <th>according</th>\n",
       "      <th>account</th>\n",
       "      <th>...</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yr</th>\n",
       "      <th>z</th>\n",
       "      <th>zaporizhzhia</th>\n",
       "      <th>zaporozhye</th>\n",
       "      <th>zelenskiy</th>\n",
       "      <th>zelensky</th>\n",
       "      <th>zelenskys</th>\n",
       "      <th>zelenskyy</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57857</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57858</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57859</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57860</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57861</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57862 rows √ó 2129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       abandoned  ability  able  absolute  absolutely  accept  access  \\\n",
       "0            0.0      0.0   0.0       0.0         0.0     0.0     0.0   \n",
       "1            0.0      0.0   0.0       0.0         0.0     0.0     0.0   \n",
       "2            0.0      0.0   0.0       0.0         0.0     0.0     0.0   \n",
       "3            0.0      0.0   0.0       0.0         0.0     0.0     0.0   \n",
       "4            0.0      0.0   0.0       0.0         0.0     0.0     0.0   \n",
       "...          ...      ...   ...       ...         ...     ...     ...   \n",
       "57857        0.0      0.0   0.0       0.0         0.0     0.0     0.0   \n",
       "57858        0.0      0.0   0.0       0.0         0.0     0.0     0.0   \n",
       "57859        0.0      0.0   0.0       0.0         0.0     0.0     0.0   \n",
       "57860        0.0      0.0   0.0       0.0         0.0     0.0     0.0   \n",
       "57861        0.0      0.0   0.0       0.0         0.0     0.0     0.0   \n",
       "\n",
       "       accident  according  account  ...  youtube   yr    z  zaporizhzhia  \\\n",
       "0           0.0        0.0      0.0  ...      0.0  0.0  0.0           0.0   \n",
       "1           0.0        0.0      0.0  ...      0.0  0.0  0.0           0.0   \n",
       "2           0.0        0.0      0.0  ...      0.0  0.0  0.0           0.0   \n",
       "3           0.0        0.0      0.0  ...      0.0  0.0  0.0           0.0   \n",
       "4           0.0        0.0      0.0  ...      0.0  0.0  0.0           0.0   \n",
       "...         ...        ...      ...  ...      ...  ...  ...           ...   \n",
       "57857       0.0        0.0      0.0  ...      0.0  0.0  0.0           0.0   \n",
       "57858       0.0        0.0      0.0  ...      0.0  0.0  0.0           0.0   \n",
       "57859       0.0        0.0      0.0  ...      0.0  0.0  0.0           0.0   \n",
       "57860       0.0        0.0      0.0  ...      0.0  0.0  0.0           0.0   \n",
       "57861       0.0        0.0      0.0  ...      0.0  0.0  0.0           0.0   \n",
       "\n",
       "       zaporozhye  zelenskiy  zelensky  zelenskys  zelenskyy  zone  \n",
       "0             0.0        0.0       0.0        0.0        0.0   0.0  \n",
       "1             0.0        0.0       0.0        0.0        0.0   0.0  \n",
       "2             0.0        0.0       0.0        0.0        0.0   0.0  \n",
       "3             0.0        0.0       0.0        0.0        0.0   0.0  \n",
       "4             0.0        0.0       0.0        0.0        0.0   0.0  \n",
       "...           ...        ...       ...        ...        ...   ...  \n",
       "57857         0.0        0.0       0.0        0.0        0.0   0.0  \n",
       "57858         0.0        0.0       0.0        0.0        0.0   0.0  \n",
       "57859         0.0        0.0       0.0        0.0        0.0   0.0  \n",
       "57860         0.0        0.0       0.0        0.0        0.0   0.0  \n",
       "57861         0.0        0.0       0.0        0.0        0.0   0.0  \n",
       "\n",
       "[57862 rows x 2129 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tf_idf = pd.DataFrame(tf, columns = tf_features_names)\n",
    "\n",
    "df_tf_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating our final Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop unnecessary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = df.drop(['media','Polarity Score','user_created','Date of Creation in months','Date of Tweet in Months',\n",
    "         'hashtags', 'lang', 'mentionedUsers'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('../Data/Processed Dataset.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
