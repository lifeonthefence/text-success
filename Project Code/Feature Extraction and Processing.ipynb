{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Data/Ukraine Tweets.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset = 'id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precounting of features: Length, Hashtags, URLs and Mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet_length'] = df['rendered_content'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_mentions'] = df['rendered_content'].apply(lambda x: x.count('@'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_hashtags'] = df['rendered_content'].apply(lambda x: x.count('#'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_urls'] = df['rendered_content'].apply(lambda x: x.count('https'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps taken:\n",
    "- Converting emojis to text\n",
    "- We decide to remove all the mentions and hashtagged words, as these will be analysed separately\n",
    "- Remove Links, as these don't contribute to SA\n",
    "- Conducting the SA on our preprocessed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a new column so that we can see the adjusted tweet and original versiom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(loc=6,\n",
    "          column='Adjusted Tweet',\n",
    "          value=df['rendered_content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting emojis to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "\n",
    "def demote(text):\n",
    "    text = emoji.demojize(text)\n",
    "    return text\n",
    "\n",
    "df['Adjusted Tweet'] = df['Adjusted Tweet'].apply(demote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing mentions and hashtagged words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_mentions_hashtags(text):\n",
    "    text = re.sub(\"@[A-Za-z0-9_]+\",\"\", text)\n",
    "    text = re.sub(\"#[A-Za-z0-9_]+\",\"\", text)\n",
    "    return text\n",
    "\n",
    "df['Adjusted Tweet'] = df['Adjusted Tweet'].apply(remove_mentions_hashtags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_links(text):\n",
    "    text = re.sub('http://\\S+|https://\\S+', '', text)\n",
    "    text = re.sub('http[s]?://\\S+', '', text)\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    text = re.sub(r'bit.ly/\\S+', '', text) # remove bitly links\n",
    "    text = text.strip('[link]') # remove [links]\n",
    "    return text\n",
    "\n",
    "df['Adjusted Tweet'] = df['Adjusted Tweet'].apply(remove_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert Polarity Score Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(loc=7,\n",
    "          column='Polarity Score',\n",
    "          value=df['Adjusted Tweet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment Analysis using NLTK's VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Uncomment to download lexicon for the first time \n",
    "#import nltk\n",
    "#nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def sentiment_analysis(text):  \n",
    "    text = sia.polarity_scores(text)\n",
    "    return text\n",
    "\n",
    "df['Polarity Score'] = df['Polarity Score'].apply(sentiment_analysis)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating columns for:\n",
    "- Negative Score\n",
    "- Neutral Score\n",
    "- Positive Score\n",
    "- Compound Score [-1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(loc=8,\n",
    "          column='Negative Score',\n",
    "          value=df['Polarity Score'])\n",
    "\n",
    "df.insert(loc=9,\n",
    "          column='Neutral Score',\n",
    "          value=df['Polarity Score'])\n",
    "\n",
    "df.insert(loc=10,\n",
    "          column='Positive Score',\n",
    "          value=df['Polarity Score'])\n",
    "\n",
    "df.insert(loc=11,\n",
    "          column='Compound Score',\n",
    "          value=df['Polarity Score'])\n",
    "\n",
    "df['Negative Score'] = df['Negative Score'].apply(lambda x: x['neg'])\n",
    "df['Neutral Score'] = df['Neutral Score'].apply(lambda x: x['neu'])\n",
    "df['Positive Score'] = df['Positive Score'].apply(lambda x: x['pos'])\n",
    "df['Compound Score'] = df['Compound Score'].apply(lambda x: x['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>user</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>user_created</th>\n",
       "      <th>rendered_content</th>\n",
       "      <th>Adjusted Tweet</th>\n",
       "      <th>Polarity Score</th>\n",
       "      <th>Negative Score</th>\n",
       "      <th>Neutral Score</th>\n",
       "      <th>...</th>\n",
       "      <th>replies</th>\n",
       "      <th>quoteCount</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>lang</th>\n",
       "      <th>media</th>\n",
       "      <th>mentionedUsers</th>\n",
       "      <th>tweet_length</th>\n",
       "      <th>num_mentions</th>\n",
       "      <th>num_hashtags</th>\n",
       "      <th>num_urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1477420789863436289</td>\n",
       "      <td>2022-01-01 23:25:40+00:00</td>\n",
       "      <td>anno1540</td>\n",
       "      <td>8838</td>\n",
       "      <td>2014-06-12 17:05:22+00:00</td>\n",
       "      <td>Lithuania will never abandon Ukraine, voluntee...</td>\n",
       "      <td>Lithuania will never abandon Ukraine, voluntee...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.661, 'pos': 0.339, 'comp...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.661</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['Lithuania', 'Ukraine']</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1477414596424220679</td>\n",
       "      <td>2022-01-01 23:01:03+00:00</td>\n",
       "      <td>weather_odessa</td>\n",
       "      <td>119</td>\n",
       "      <td>2019-07-10 08:34:22+00:00</td>\n",
       "      <td>#odessa #odesa #ukraine #одесса\\nNow: 4.2°C\\nT...</td>\n",
       "      <td>#одесса\\nNow: 4.2°C\\nToday's Min: 4.2°C at ...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['odessa', 'odesa', 'ukraine', 'одесса']</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1477414332376010752</td>\n",
       "      <td>2022-01-01 23:00:00+00:00</td>\n",
       "      <td>AlArabiya_Eng</td>\n",
       "      <td>927174</td>\n",
       "      <td>2009-02-28 08:31:32+00:00</td>\n",
       "      <td>After tough talk between Presidents Joe Biden ...</td>\n",
       "      <td>After tough talk between Presidents Joe Biden ...</td>\n",
       "      <td>{'neg': 0.099, 'neu': 0.776, 'pos': 0.125, 'co...</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.776</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>['Russia', 'Ukraine']</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>277</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1477409748572151809</td>\n",
       "      <td>2022-01-01 22:41:47+00:00</td>\n",
       "      <td>beatravelling</td>\n",
       "      <td>6329</td>\n",
       "      <td>2014-02-28 21:25:33+00:00</td>\n",
       "      <td>The beach can be nice in the fall too 😊🇺🇦\\n\\n#...</td>\n",
       "      <td>The beach can be nice in the fall too :smiling...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.781, 'pos': 0.219, 'comp...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.781</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['lanzheron', 'langeron', 'beach', 'odessa', '...</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1477409332820119552</td>\n",
       "      <td>2022-01-01 22:40:08+00:00</td>\n",
       "      <td>TornCurtain1991</td>\n",
       "      <td>677</td>\n",
       "      <td>2012-02-08 15:30:41+00:00</td>\n",
       "      <td>A note: Stepan #Bandera, DOB 01011909, was lea...</td>\n",
       "      <td>A note: Stepan , DOB 01011909, was leader of O...</td>\n",
       "      <td>{'neg': 0.171, 'neu': 0.829, 'pos': 0.0, 'comp...</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.829</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['Bandera', 'Ukraine']</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>278</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                       date             user  \\\n",
       "0  1477420789863436289  2022-01-01 23:25:40+00:00         anno1540   \n",
       "1  1477414596424220679  2022-01-01 23:01:03+00:00   weather_odessa   \n",
       "2  1477414332376010752  2022-01-01 23:00:00+00:00    AlArabiya_Eng   \n",
       "3  1477409748572151809  2022-01-01 22:41:47+00:00    beatravelling   \n",
       "4  1477409332820119552  2022-01-01 22:40:08+00:00  TornCurtain1991   \n",
       "\n",
       "   user_followers               user_created  \\\n",
       "0            8838  2014-06-12 17:05:22+00:00   \n",
       "1             119  2019-07-10 08:34:22+00:00   \n",
       "2          927174  2009-02-28 08:31:32+00:00   \n",
       "3            6329  2014-02-28 21:25:33+00:00   \n",
       "4             677  2012-02-08 15:30:41+00:00   \n",
       "\n",
       "                                    rendered_content  \\\n",
       "0  Lithuania will never abandon Ukraine, voluntee...   \n",
       "1  #odessa #odesa #ukraine #одесса\\nNow: 4.2°C\\nT...   \n",
       "2  After tough talk between Presidents Joe Biden ...   \n",
       "3  The beach can be nice in the fall too 😊🇺🇦\\n\\n#...   \n",
       "4  A note: Stepan #Bandera, DOB 01011909, was lea...   \n",
       "\n",
       "                                      Adjusted Tweet  \\\n",
       "0  Lithuania will never abandon Ukraine, voluntee...   \n",
       "1     #одесса\\nNow: 4.2°C\\nToday's Min: 4.2°C at ...   \n",
       "2  After tough talk between Presidents Joe Biden ...   \n",
       "3  The beach can be nice in the fall too :smiling...   \n",
       "4  A note: Stepan , DOB 01011909, was leader of O...   \n",
       "\n",
       "                                      Polarity Score  Negative Score  \\\n",
       "0  {'neg': 0.0, 'neu': 0.661, 'pos': 0.339, 'comp...           0.000   \n",
       "1  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...           0.000   \n",
       "2  {'neg': 0.099, 'neu': 0.776, 'pos': 0.125, 'co...           0.099   \n",
       "3  {'neg': 0.0, 'neu': 0.781, 'pos': 0.219, 'comp...           0.000   \n",
       "4  {'neg': 0.171, 'neu': 0.829, 'pos': 0.0, 'comp...           0.171   \n",
       "\n",
       "   Neutral Score  ...  replies  quoteCount  \\\n",
       "0          0.661  ...        0           0   \n",
       "1          1.000  ...        0           0   \n",
       "2          0.776  ...        3           0   \n",
       "3          0.781  ...        0           0   \n",
       "4          0.829  ...        0           0   \n",
       "\n",
       "                                            hashtags  lang  media  \\\n",
       "0                           ['Lithuania', 'Ukraine']    en    NaN   \n",
       "1           ['odessa', 'odesa', 'ukraine', 'одесса']    en    NaN   \n",
       "2                              ['Russia', 'Ukraine']    en    NaN   \n",
       "3  ['lanzheron', 'langeron', 'beach', 'odessa', '...    en    NaN   \n",
       "4                             ['Bandera', 'Ukraine']    en    NaN   \n",
       "\n",
       "   mentionedUsers tweet_length num_mentions num_hashtags num_urls  \n",
       "0             NaN          132            0            2        0  \n",
       "1             NaN          188            0            4        0  \n",
       "2             NaN          277            0            2        0  \n",
       "3             NaN          122            0            5        0  \n",
       "4             NaN          278            0            2        0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment Analysis using TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(loc=12,\n",
    "          column='Polarity Score_textblob',\n",
    "          value=df['Adjusted Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(loc=13,\n",
    "          column='Subjectivity Score_textblob',\n",
    "          value=df['Adjusted Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "#Create a function to get the subjectivity\n",
    "def getSubjectivity(text):\n",
    "    return TextBlob(text).sentiment.subjectivity\n",
    "\n",
    "#Create a function to get the polarity\n",
    "def getPolarity(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "df['Polarity Score_textblob'] = df['Polarity Score_textblob'].apply(getPolarity)\n",
    "df['Subjectivity Score_textblob'] = df['Subjectivity Score_textblob'].apply(getSubjectivity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further manipulating the tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps taken:\n",
    "- Lowercase\n",
    "- Punctuation\n",
    "- Tokenization\n",
    "- Stopword filtering\n",
    "- Lemmatisation\n",
    "- Number removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing all text to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Adjusted Tweet'] = df['Adjusted Tweet'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing all Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def punctuation_remove(text):\n",
    "    text = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    return text\n",
    "\n",
    "df['Adjusted Tweet'] = df['Adjusted Tweet'].apply(punctuation_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_numbers(text):\n",
    "    no_numbers = re.sub(r'\\d+', '', text)\n",
    "    return no_numbers\n",
    "\n",
    "df['Adjusted Tweet'] = df['Adjusted Tweet'].apply(remove_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "def tokenize(text):\n",
    "    text = word_tokenize(text)\n",
    "    return text\n",
    "\n",
    "df['Adjusted Tweet'] = df['Adjusted Tweet'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopword Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stop_words = stopwords.words('english')\n",
    "    text = [word for word in text if word not in stop_words]\n",
    "    return text\n",
    "\n",
    "df['Adjusted Tweet'] = df['Adjusted Tweet'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "def lemmatise(text): \n",
    "    lemma = [wnl.lemmatize(word) for word in text]\n",
    "    return lemma\n",
    "\n",
    "df['Adjusted Tweet'] = df['Adjusted Tweet'].apply(lemmatise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Months since creation of account relative to tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding date of account creation in months\n",
    "df.insert(loc=5,\n",
    "          column='Date of Creation in months',\n",
    "          value=df['user_created'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import *\n",
    "\n",
    "#returning the months of account creation\n",
    "def account_creation(text):\n",
    "    text = datetime.strptime(text, \"%Y-%m-%d %H:%M:%S+00:00\")\n",
    "    year = str(text)[0:4]\n",
    "    month = str(text)[5:7]\n",
    "    total_months = (int(year)*12)+(int(month))\n",
    "    return (total_months)\n",
    "\n",
    "df['Date of Creation in months'] = df['Date of Creation in months'].apply(account_creation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding date of tweet in months\n",
    "df.insert(loc=6,\n",
    "          column='Date of Tweet in Months',\n",
    "          value=df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return the year of tweet\n",
    "df['Date of Tweet in Months'] = df['Date of Tweet in Months'].apply(account_creation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating Months since creation of account relative to tweet\n",
    "df.insert(loc=7,\n",
    "          column='Months Since Creation of Account',\n",
    "          value= (df['Date of Tweet in Months']-df['Date of Creation in months']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time of Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a column for hours:\n",
    "df.insert(loc=2,\n",
    "          column='hour of tweet',\n",
    "          value=df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "#return the hour of the tweet\n",
    "def hour(text):\n",
    "    text = datetime.strptime(text, \"%Y-%m-%d %H:%M:%S+00:00\")\n",
    "    hour = str(text.time())[0:2]\n",
    "    return int(hour)\n",
    "\n",
    "df['hour of tweet'] = df['hour of tweet'].apply(hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert column for the time of day\n",
    "df.insert(loc=3,\n",
    "          column='time of day',\n",
    "          value=df['hour of tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the time of day\n",
    "def time_of_day(text):  \n",
    "    if ((text > 4) and (text < 8 )):\n",
    "        return 'Early Morning'\n",
    "    elif ((text > 8) and (text < 12 )):\n",
    "        return 'Morning'\n",
    "    elif ((text > 12) and (text < 16 )):\n",
    "        return 'Noon'\n",
    "    elif ((text > 16) and (text < 20 )):\n",
    "        return 'Eve'\n",
    "    elif ((text > 20) and (text < 24 )):\n",
    "        return 'Night'\n",
    "    elif ((text > 0) and (text < 4 )):\n",
    "        return 'Late Night'\n",
    "    \n",
    "df['time of day'] = df['time of day'].apply(time_of_day)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating counts using one hot encoding\n",
    "\n",
    "#Early Morning Count\n",
    "df.insert(loc=4,\n",
    "          column='Early Morning Count',\n",
    "          value=df['time of day'])\n",
    "\n",
    "def early_morning_count(text):\n",
    "    if text == 'Early Morning':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df['Early Morning Count'] = df['Early Morning Count'].apply(early_morning_count)\n",
    "\n",
    "#Morning Count\n",
    "df.insert(loc=5,\n",
    "          column='Morning Count',\n",
    "          value=df['time of day'])\n",
    "\n",
    "def morning_count(text):\n",
    "    if text == 'Morning':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df['Morning Count'] = df['Morning Count'].apply(morning_count)\n",
    "\n",
    "#Noon count\n",
    "df.insert(loc=6,\n",
    "          column='Noon Count',\n",
    "          value=df['time of day'])\n",
    "\n",
    "def noon_count(text):\n",
    "    if text == 'Noon':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df['Noon Count'] = df['Noon Count'].apply(noon_count)\n",
    "\n",
    "#Eve count\n",
    "df.insert(loc=7,\n",
    "          column='Eve Count',\n",
    "          value=df['time of day'])\n",
    "\n",
    "def eve_count(text):\n",
    "    if text == 'Eve':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df['Eve Count'] = df['Eve Count'].apply(eve_count)\n",
    "\n",
    "#Night count\n",
    "df.insert(loc=8,\n",
    "          column='Night Count',\n",
    "          value=df['time of day'])\n",
    "\n",
    "def night_count(text):\n",
    "    if text == 'Night':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df['Night Count'] = df['Night Count'].apply(night_count)\n",
    "\n",
    "#Late Night count\n",
    "df.insert(loc=9,\n",
    "          column='Late Night Count',\n",
    "          value=df['time of day'])\n",
    "\n",
    "def late_night_count(text):\n",
    "    if text == 'Late Night':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df['Late Night Count'] = df['Late Night Count'].apply(late_night_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video, GIF and Photo Count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Photo Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a photo count column...\n",
    "df.insert(loc=23,\n",
    "          column='Photo Count',\n",
    "          value=df['media'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counting number of Photos in media column\n",
    "#No need to tokenize\n",
    "def photo_count(text):\n",
    "    text = str(text)\n",
    "    text = text.count('Photo')\n",
    "    return text\n",
    "\n",
    "df['Photo Count'] = df['Photo Count'].apply(photo_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Video Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a video count column...\n",
    "df.insert(loc=24,\n",
    "          column='Video Count',\n",
    "          value=df['media'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need to tokenize the media column so that we can count how many videos there are...\n",
    "from nltk import word_tokenize\n",
    "\n",
    "def tokenize(text):\n",
    "    text = str(text)\n",
    "    text = word_tokenize(text)\n",
    "    return text\n",
    "\n",
    "df['Video Count'] = df['Video Count'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counting number of Videos in media column\n",
    "def video_count(text):\n",
    "    text = text.count('Video')\n",
    "    return text\n",
    "\n",
    "df['Video Count'] = df['Video Count'].apply(video_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gif Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a GIF count column...\n",
    "df.insert(loc=25,\n",
    "          column='GIF Count',\n",
    "          value=df['media'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need to tokenize the media column so that we can count how many GIFs there are...\n",
    "from nltk import word_tokenize\n",
    "\n",
    "def tokenize(text):\n",
    "    text = str(text)\n",
    "    text = word_tokenize(text)\n",
    "    return text\n",
    "\n",
    "df['GIF Count'] = df['GIF Count'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counting number of GIFs in media column\n",
    "def gif_count(text):\n",
    "    text = text.count('Gif')\n",
    "    return text\n",
    "\n",
    "df['GIF Count'] = df['GIF Count'].apply(gif_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def dummy(x):\n",
    "    return x\n",
    "\n",
    "vectorizer = CountVectorizer(max_df = 0.9, min_df = 25, lowercase = False, tokenizer = dummy)\n",
    "tf = vectorizer.fit_transform(df['Adjusted Tweet']).toarray()\n",
    "tf_features_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "number_of_topics = 3\n",
    "\n",
    "model = LatentDirichletAllocation(n_components=number_of_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(n_components=3)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    topic_dict = {}\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        topic_dict[\"Topic %d words\" % (topic_idx)]= ['{}'.format(feature_names[i])\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]\n",
    "        topic_dict[\"Topic %d weights\" % (topic_idx)]= ['{:.1f}'.format(topic[i])\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]\n",
    "    return pd.DataFrame(topic_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 0 words</th>\n",
       "      <th>Topic 0 weights</th>\n",
       "      <th>Topic 1 words</th>\n",
       "      <th>Topic 1 weights</th>\n",
       "      <th>Topic 2 words</th>\n",
       "      <th>Topic 2 weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#coinbase</td>\n",
       "      <td>2314.8</td>\n",
       "      <td>grid</td>\n",
       "      <td>8595.3</td>\n",
       "      <td>ours</td>\n",
       "      <td>7839.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>east</td>\n",
       "      <td>2071.3</td>\n",
       "      <td>membership</td>\n",
       "      <td>6647.4</td>\n",
       "      <td>membership</td>\n",
       "      <td>6827.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>national</td>\n",
       "      <td>1904.2</td>\n",
       "      <td>mi</td>\n",
       "      <td>4894.9</td>\n",
       "      <td>national</td>\n",
       "      <td>4885.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>membership</td>\n",
       "      <td>1602.9</td>\n",
       "      <td>agent</td>\n",
       "      <td>3823.2</td>\n",
       "      <td>grenades</td>\n",
       "      <td>4874.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>club</td>\n",
       "      <td>1589.0</td>\n",
       "      <td>grenades</td>\n",
       "      <td>2124.0</td>\n",
       "      <td>meet</td>\n",
       "      <td>3025.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>discovered</td>\n",
       "      <td>1411.6</td>\n",
       "      <td>crossing</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>fascism</td>\n",
       "      <td>2587.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>occupying</td>\n",
       "      <td>1331.8</td>\n",
       "      <td>forbes</td>\n",
       "      <td>1947.9</td>\n",
       "      <td>out</td>\n",
       "      <td>2086.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mi</td>\n",
       "      <td>1171.5</td>\n",
       "      <td>#freedomofrussia</td>\n",
       "      <td>1718.6</td>\n",
       "      <td>outcome</td>\n",
       "      <td>2026.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>live</td>\n",
       "      <td>1093.3</td>\n",
       "      <td>credit</td>\n",
       "      <td>1716.9</td>\n",
       "      <td>#coinbase</td>\n",
       "      <td>1979.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>announce</td>\n",
       "      <td>1014.8</td>\n",
       "      <td>important</td>\n",
       "      <td>1594.5</td>\n",
       "      <td>grid</td>\n",
       "      <td>1616.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Topic 0 words Topic 0 weights     Topic 1 words Topic 1 weights  \\\n",
       "0     #coinbase          2314.8              grid          8595.3   \n",
       "1          east          2071.3        membership          6647.4   \n",
       "2      national          1904.2                mi          4894.9   \n",
       "3    membership          1602.9             agent          3823.2   \n",
       "4          club          1589.0          grenades          2124.0   \n",
       "5    discovered          1411.6          crossing          1997.0   \n",
       "6     occupying          1331.8            forbes          1947.9   \n",
       "7            mi          1171.5  #freedomofrussia          1718.6   \n",
       "8          live          1093.3            credit          1716.9   \n",
       "9      announce          1014.8         important          1594.5   \n",
       "\n",
       "  Topic 2 words Topic 2 weights  \n",
       "0          ours          7839.0  \n",
       "1    membership          6827.7  \n",
       "2      national          4885.2  \n",
       "3      grenades          4874.6  \n",
       "4          meet          3025.4  \n",
       "5       fascism          2587.8  \n",
       "6           out          2086.0  \n",
       "7       outcome          2026.2  \n",
       "8     #coinbase          1979.2  \n",
       "9          grid          1616.5  "
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_top_words = 10\n",
    "display_topics(model, tf_feature_names, no_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\miniconda3\\envs\\python\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:312: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn((\"The 'init' value, when 'init=None' and \"\n",
      "C:\\Users\\david\\miniconda3\\envs\\python\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1090: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\"Maximum number of iterations %d reached. Increase it to\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.1, l1_ratio=0.5, n_components=4, random_state=0)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "model_2 = NMF(n_components=4, random_state=0, alpha=.1, l1_ratio=.5)\n",
    "\n",
    "model_2.fit(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 0 words</th>\n",
       "      <th>Topic 0 weights</th>\n",
       "      <th>Topic 1 words</th>\n",
       "      <th>Topic 1 weights</th>\n",
       "      <th>Topic 2 words</th>\n",
       "      <th>Topic 2 weights</th>\n",
       "      <th>Topic 3 words</th>\n",
       "      <th>Topic 3 weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>membership</td>\n",
       "      <td>19.1</td>\n",
       "      <td>ours</td>\n",
       "      <td>15.0</td>\n",
       "      <td>grid</td>\n",
       "      <td>15.2</td>\n",
       "      <td>national</td>\n",
       "      <td>13.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>meet</td>\n",
       "      <td>2.0</td>\n",
       "      <td>out</td>\n",
       "      <td>2.1</td>\n",
       "      <td>mi</td>\n",
       "      <td>6.2</td>\n",
       "      <td>grenades</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>grenades</td>\n",
       "      <td>1.9</td>\n",
       "      <td>outcome</td>\n",
       "      <td>2.0</td>\n",
       "      <td>agent</td>\n",
       "      <td>3.5</td>\n",
       "      <td>#coinbase</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>august</td>\n",
       "      <td>1.5</td>\n",
       "      <td>our</td>\n",
       "      <td>1.9</td>\n",
       "      <td>important</td>\n",
       "      <td>1.4</td>\n",
       "      <td>meet</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>east</td>\n",
       "      <td>1.4</td>\n",
       "      <td>fascism</td>\n",
       "      <td>1.1</td>\n",
       "      <td>credit</td>\n",
       "      <td>1.4</td>\n",
       "      <td>fascism</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ended</td>\n",
       "      <td>1.2</td>\n",
       "      <td>#coinbase</td>\n",
       "      <td>0.9</td>\n",
       "      <td>manpads</td>\n",
       "      <td>1.2</td>\n",
       "      <td>occupying</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>coast</td>\n",
       "      <td>1.1</td>\n",
       "      <td>happening</td>\n",
       "      <td>0.5</td>\n",
       "      <td>crossing</td>\n",
       "      <td>1.2</td>\n",
       "      <td>democracy</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>african</td>\n",
       "      <td>1.1</td>\n",
       "      <td>east</td>\n",
       "      <td>0.5</td>\n",
       "      <td>forbes</td>\n",
       "      <td>1.1</td>\n",
       "      <td>#uvalde</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>#eurovision</td>\n",
       "      <td>1.0</td>\n",
       "      <td>#uvalde</td>\n",
       "      <td>0.5</td>\n",
       "      <td>#freedomofrussia</td>\n",
       "      <td>1.0</td>\n",
       "      <td>out</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>agent</td>\n",
       "      <td>0.8</td>\n",
       "      <td>meet</td>\n",
       "      <td>0.5</td>\n",
       "      <td>#estonia</td>\n",
       "      <td>1.0</td>\n",
       "      <td>outcome</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Topic 0 words Topic 0 weights Topic 1 words Topic 1 weights  \\\n",
       "0    membership            19.1          ours            15.0   \n",
       "1          meet             2.0           out             2.1   \n",
       "2      grenades             1.9       outcome             2.0   \n",
       "3        august             1.5           our             1.9   \n",
       "4          east             1.4       fascism             1.1   \n",
       "5         ended             1.2     #coinbase             0.9   \n",
       "6         coast             1.1     happening             0.5   \n",
       "7       african             1.1          east             0.5   \n",
       "8   #eurovision             1.0       #uvalde             0.5   \n",
       "9         agent             0.8          meet             0.5   \n",
       "\n",
       "      Topic 2 words Topic 2 weights Topic 3 words Topic 3 weights  \n",
       "0              grid            15.2      national            13.1  \n",
       "1                mi             6.2      grenades             8.3  \n",
       "2             agent             3.5     #coinbase             4.7  \n",
       "3         important             1.4          meet             2.3  \n",
       "4            credit             1.4       fascism             1.8  \n",
       "5           manpads             1.2     occupying             1.5  \n",
       "6          crossing             1.2     democracy             1.0  \n",
       "7            forbes             1.1       #uvalde             1.0  \n",
       "8  #freedomofrussia             1.0           out             0.9  \n",
       "9          #estonia             1.0       outcome             0.9  "
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_topics(model_2, tf_feature_names, no_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like these clustering algorithms do not pick up any interesting clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating our final Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop unnecessary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = df.drop(['media','Polarity Score','user_created','Date of Creation in months','Date of Tweet in Months',\n",
    "         'hashtags', 'lang', 'mentionedUsers'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('../Data/Processed Dataset.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
