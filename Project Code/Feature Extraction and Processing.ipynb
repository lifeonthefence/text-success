{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "from textblob import TextBlob \n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import twitter_samples\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import nltk\n",
    "\n",
    "from argparse import Namespace\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/harveymiller/Documents/GitHub/text-success/Data/Ukraine Tweets.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps taken:\n",
    "- Converting emojis to text\n",
    "- We decide to remove all the mentions and hashtagged words, as these will be analysed separately\n",
    "- Remove Links, as these don't contribute to SA\n",
    "- Conducting the SA on our preprocessed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a new column so that we can see the adjusted tweet and original versiom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(loc=6,\n",
    "          column='Adjusted Tweet',\n",
    "          value=df['rendered_content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting emojis to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emot\n",
    "import emoji\n",
    "\n",
    "def demote(text):\n",
    "    text = emoji.demojize(text)\n",
    "    return text\n",
    "\n",
    "df['Adjusted Tweet'] = df['Adjusted Tweet'].apply(demote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing mentions and hashtagged words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_mentions_hashtags(text):\n",
    "    text = re.sub(\"@[A-Za-z0-9_]+\",\"\", text)\n",
    "    text = re.sub(\"#[A-Za-z0-9_]+\",\"\", text)\n",
    "    return text\n",
    "\n",
    "df['Adjusted Tweet'] = df['Adjusted Tweet'].apply(remove_mentions_hashtags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_links(text):\n",
    "    text = re.sub('http://\\S+|https://\\S+', '', text)\n",
    "    text = re.sub('http[s]?://\\S+', '', text)\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    text = re.sub(r'bit.ly/\\S+', '', text) # remove bitly links\n",
    "    text = text.strip('[link]') # remove [links]\n",
    "    return text\n",
    "\n",
    "df['Adjusted Tweet'] = df['Adjusted Tweet'].apply(remove_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert Polarity Score Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(loc=7,\n",
    "          column='Polarity Score',\n",
    "          value=df['Adjusted Tweet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment Analysis using NLTK's VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def sentiment_analysis(text):  \n",
    "    text = sia.polarity_scores(text)\n",
    "    return text\n",
    "\n",
    "df['Polarity Score'] = df['Polarity Score'].apply(sentiment_analysis)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating columns for:\n",
    "- Negative Score\n",
    "- Neutral Score\n",
    "- Positive Score\n",
    "- Compound Score [-1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(loc=8,\n",
    "          column='Negative Score',\n",
    "          value=df['Polarity Score'])\n",
    "\n",
    "df.insert(loc=9,\n",
    "          column='Neutral Score',\n",
    "          value=df['Polarity Score'])\n",
    "\n",
    "df.insert(loc=10,\n",
    "          column='Positive Score',\n",
    "          value=df['Polarity Score'])\n",
    "\n",
    "df.insert(loc=11,\n",
    "          column='Compound Score',\n",
    "          value=df['Polarity Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_score(text):\n",
    "    text = text['neg']\n",
    "    return text\n",
    "\n",
    "df['Negative Score'] = df['Negative Score'].apply(negative_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neutral_score(text):\n",
    "    text = text['neu']\n",
    "    return text\n",
    "\n",
    "df['Neutral Score'] = df['Neutral Score'].apply(neutral_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive_score(text):\n",
    "    text = text['pos']\n",
    "    return text\n",
    "\n",
    "df['Positive Score'] = df['Positive Score'].apply(positive_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compound_score(text):\n",
    "    text = text['compound']\n",
    "    return text\n",
    "\n",
    "df['Compound Score'] = df['Compound Score'].apply(compound_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment Analysis using TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(loc=12,\n",
    "          column='Polarity Score_textblob',\n",
    "          value=df['Adjusted Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(loc=13,\n",
    "          column='Subjectivity Score_textblob',\n",
    "          value=df['Adjusted Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "#Create a function to get the subjectivity\n",
    "def getSubjectivity(text):\n",
    "    return TextBlob(text).sentiment.subjectivity\n",
    "\n",
    "#Create a function to get the polarity\n",
    "def getPolarity(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "df['Polarity Score_textblob'] = df['Polarity Score_textblob'].apply(getPolarity)\n",
    "df['Subjectivity Score_textblob'] = df['Subjectivity Score_textblob'].apply(getSubjectivity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further manipulating the tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps taken:\n",
    "- Lowercase\n",
    "- Punctuation\n",
    "- Tokenization\n",
    "- Stopword filtering\n",
    "- Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing all text to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowercase(text):    \n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "df['Adjusted Tweet'] = df['Adjusted Tweet'].apply(lowercase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing all Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def punctuation_remove(text):\n",
    "    text = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    return text\n",
    "\n",
    "df['Adjusted Tweet'] = df['Adjusted Tweet'].apply(punctuation_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "def tokenize(text):\n",
    "    text = word_tokenize(text)\n",
    "    return text\n",
    "\n",
    "df['Adjusted Tweet'] = df['Adjusted Tweet'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopword Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stop_words = stopwords.words('english')\n",
    "    text = [word for word in text if word not in stop_words]\n",
    "    return text\n",
    "\n",
    "df['Adjusted Tweet'] = df['Adjusted Tweet'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "\n",
    "def stem(text):\n",
    "    stemmed = [porter.stem(word) for word in text]\n",
    "    return text\n",
    "\n",
    "df['Adjusted Tweet'] = df['Adjusted Tweet'].apply(stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Months since creation of account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding year of creation\n",
    "df.insert(loc=5,\n",
    "          column='Year of Creation',\n",
    "          value=df['user_created'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import *\n",
    "\n",
    "#return the year of account creation\n",
    "def account_creation(text):\n",
    "    text = datetime.strptime(text, \"%Y-%m-%d %H:%M:%S+00:00\")\n",
    "    hour = str(text)[0:4]\n",
    "    return int(hour)\n",
    "\n",
    "df['Year of Creation'] = df['Year of Creation'].apply(account_creation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding year of tweet\n",
    "df.insert(loc=6,\n",
    "          column='Year of Tweet',\n",
    "          value=df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import *\n",
    "\n",
    "#return the year of tweet\n",
    "df['Year of Tweet'] = df['Year of Tweet'].apply(account_creation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time of Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a column for hours:\n",
    "df.insert(loc=2,\n",
    "          column='hour of tweet',\n",
    "          value=df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import *\n",
    "\n",
    "#return the hour of the tweet\n",
    "def hour(text):\n",
    "    text = datetime.strptime(text, \"%Y-%m-%d %H:%M:%S+00:00\")\n",
    "    hour = str(text.time())[0:2]\n",
    "    return int(hour)\n",
    "\n",
    "df['hour of tweet'] = df['hour of tweet'].apply(hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert column for the time of day\n",
    "df.insert(loc=3,\n",
    "          column='time of day',\n",
    "          value=df['hour of tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_of_day(text):  \n",
    "    if ((text < 4) & (text > 8 )):\n",
    "        return 'Early Morning'\n",
    "    elif ((text < 8) & (text > 12 )):\n",
    "        return 'Morning'\n",
    "    elif ((text < 12) & (text > 16 )):\n",
    "        return 'Noon'\n",
    "    elif ((text < 16) & (text > 20 )):\n",
    "        return 'Eve'\n",
    "    elif ((text < 20) & (text > 24 )):\n",
    "        return 'Night'\n",
    "    elif ((text < 24) & (text > 4 )):\n",
    "        return 'Late Night'\n",
    "    \n",
    "\n",
    "df['time of day'] = df['time of day'].apply(time_of_day)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video, GIF and Photo Count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Photo Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a photo count column...\n",
    "df.insert(loc=23,\n",
    "          column='Photo Count',\n",
    "          value=df['media'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counting number of Photos in media column\n",
    "#No need to tokenize\n",
    "def photo_count(text):\n",
    "    text = str(text)\n",
    "    text = text.count('Photo')\n",
    "    return text\n",
    "\n",
    "df['Photo Count'] = df['Photo Count'].apply(photo_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Video Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a video count column...\n",
    "df.insert(loc=24,\n",
    "          column='Video Count',\n",
    "          value=df['media'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need to tokenize the media column so that we can count how many videos there are...\n",
    "from nltk import word_tokenize\n",
    "\n",
    "def tokenize(text):\n",
    "    text = str(text)\n",
    "    text = word_tokenize(text)\n",
    "    return text\n",
    "\n",
    "df['Video Count'] = df['Video Count'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counting number of Videos in media column\n",
    "def video_count(text):\n",
    "    text = text.count('Video')\n",
    "    return text\n",
    "\n",
    "df['Video Count'] = df['Video Count'].apply(video_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gif Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a GIF count column...\n",
    "df.insert(loc=25,\n",
    "          column='GIF Count',\n",
    "          value=df['media'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need to tokenize the media column so that we can count how many GIFs there are...\n",
    "from nltk import word_tokenize\n",
    "\n",
    "def tokenize(text):\n",
    "    text = str(text)\n",
    "    text = word_tokenize(text)\n",
    "    return text\n",
    "\n",
    "df['GIF Count'] = df['GIF Count'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counting number of GIFs in media column\n",
    "def gif_count(text):\n",
    "    text = text.count('Gif')\n",
    "    return text\n",
    "\n",
    "df['GIF Count'] = df['GIF Count'].apply(gif_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating our final Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps taken:\n",
    "- Drop: media, date, user, polarity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['media','date','user','Polarity Score'], axis=1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
