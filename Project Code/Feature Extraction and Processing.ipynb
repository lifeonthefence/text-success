{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "from textblob import TextBlob \n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import twitter_samples\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import nltk\n",
    "\n",
    "from argparse import Namespace\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps taken:\n",
    "- Converting emojis to text\n",
    "- Lowercase\n",
    "- We decide to remove all the mentions and hashtagged words, as these will be analysed separately\n",
    "- Remove Links, as these don't contribute to SA\n",
    "- Removing Punctuation\n",
    "- Tokenization\n",
    "- Stopword filtering\n",
    "- Stemming\n",
    "- Conducting the SA on our preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/harveymiller/Documents/GitHub/text-success/Data/tweets_ukraine_monthly.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a new column so that we can see the adjusted tweet and original versiom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(loc=6,\n",
    "          column='Adjusted Tweet',\n",
    "          value=df['rendered_content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>user</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>raw_content</th>\n",
       "      <th>rendered_content</th>\n",
       "      <th>Adjusted Tweet</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>replies</th>\n",
       "      <th>quoteCount</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>lang</th>\n",
       "      <th>media</th>\n",
       "      <th>mentionedUsers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1486661338390831105</td>\n",
       "      <td>2022-01-27 11:24:18+00:00</td>\n",
       "      <td>WorldToBe1</td>\n",
       "      <td>10769</td>\n",
       "      <td>#Russia-#Ukraine debate sparks fiery exchange ...</td>\n",
       "      <td>#Russia-#Ukraine debate sparks fiery exchange ...</td>\n",
       "      <td>#Russia-#Ukraine debate sparks fiery exchange ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['Russia', 'Ukraine', 'CNN', 'USA', 'EU', 'NAT...</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1486105614803775490</td>\n",
       "      <td>2022-01-25 22:36:03+00:00</td>\n",
       "      <td>embeegle</td>\n",
       "      <td>2246</td>\n",
       "      <td>Can you say pipeline?  A larger cut coming to ...</td>\n",
       "      <td>Can you say pipeline?  A larger cut coming to ...</td>\n",
       "      <td>Can you say pipeline?  A larger cut coming to ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['PutinsPuppet', 'ukrainewar']</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1486056169013661697</td>\n",
       "      <td>2022-01-25 19:19:34+00:00</td>\n",
       "      <td>Vlad_Mykhnenko</td>\n",
       "      <td>1068</td>\n",
       "      <td>Foreign exchange markets somehow are not betti...</td>\n",
       "      <td>Foreign exchange markets somehow are not betti...</td>\n",
       "      <td>Foreign exchange markets somehow are not betti...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['russianinvasion', 'ukrainewar']</td>\n",
       "      <td>en</td>\n",
       "      <td>[Photo(previewUrl='https://pbs.twimg.com/media...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1486019310069989376</td>\n",
       "      <td>2022-01-25 16:53:07+00:00</td>\n",
       "      <td>RaVe_74</td>\n",
       "      <td>5309</td>\n",
       "      <td>#borisjohnson's expertise in foreign affairs -...</td>\n",
       "      <td>#borisjohnson's expertise in foreign affairs -...</td>\n",
       "      <td>#borisjohnson's expertise in foreign affairs -...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['borisjohnson', 'freenazanin', 'BrexitShamble...</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1485989417084985347</td>\n",
       "      <td>2022-01-25 14:54:20+00:00</td>\n",
       "      <td>miamicool</td>\n",
       "      <td>1035</td>\n",
       "      <td>Seems that #ukrainewar just became that \"line ...</td>\n",
       "      <td>Seems that #ukrainewar just became that \"line ...</td>\n",
       "      <td>Seems that #ukrainewar just became that \"line ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['ukrainewar']</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                       date            user  \\\n",
       "0  1486661338390831105  2022-01-27 11:24:18+00:00      WorldToBe1   \n",
       "1  1486105614803775490  2022-01-25 22:36:03+00:00        embeegle   \n",
       "2  1486056169013661697  2022-01-25 19:19:34+00:00  Vlad_Mykhnenko   \n",
       "3  1486019310069989376  2022-01-25 16:53:07+00:00         RaVe_74   \n",
       "4  1485989417084985347  2022-01-25 14:54:20+00:00       miamicool   \n",
       "\n",
       "   user_followers                                        raw_content  \\\n",
       "0           10769  #Russia-#Ukraine debate sparks fiery exchange ...   \n",
       "1            2246  Can you say pipeline?  A larger cut coming to ...   \n",
       "2            1068  Foreign exchange markets somehow are not betti...   \n",
       "3            5309  #borisjohnson's expertise in foreign affairs -...   \n",
       "4            1035  Seems that #ukrainewar just became that \"line ...   \n",
       "\n",
       "                                    rendered_content  \\\n",
       "0  #Russia-#Ukraine debate sparks fiery exchange ...   \n",
       "1  Can you say pipeline?  A larger cut coming to ...   \n",
       "2  Foreign exchange markets somehow are not betti...   \n",
       "3  #borisjohnson's expertise in foreign affairs -...   \n",
       "4  Seems that #ukrainewar just became that \"line ...   \n",
       "\n",
       "                                      Adjusted Tweet  likes  retweets  \\\n",
       "0  #Russia-#Ukraine debate sparks fiery exchange ...      0         0   \n",
       "1  Can you say pipeline?  A larger cut coming to ...      1         1   \n",
       "2  Foreign exchange markets somehow are not betti...      1         0   \n",
       "3  #borisjohnson's expertise in foreign affairs -...      3         1   \n",
       "4  Seems that #ukrainewar just became that \"line ...      0         0   \n",
       "\n",
       "   replies  quoteCount                                           hashtags  \\\n",
       "0        0           0  ['Russia', 'Ukraine', 'CNN', 'USA', 'EU', 'NAT...   \n",
       "1        0           0                     ['PutinsPuppet', 'ukrainewar']   \n",
       "2        0           0                  ['russianinvasion', 'ukrainewar']   \n",
       "3        0           0  ['borisjohnson', 'freenazanin', 'BrexitShamble...   \n",
       "4        0           0                                     ['ukrainewar']   \n",
       "\n",
       "  lang                                              media mentionedUsers  \n",
       "0   en                                                NaN            NaN  \n",
       "1   en                                                NaN            NaN  \n",
       "2   en  [Photo(previewUrl='https://pbs.twimg.com/media...            NaN  \n",
       "3   en                                                NaN            NaN  \n",
       "4   en                                                NaN            NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting emojis to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emot\n",
    "import emoji\n",
    "\n",
    "def demote(text):\n",
    "    text = emoji.demojize(text)\n",
    "    return text\n",
    "\n",
    "df['Adjusted Tweet'] = df['Adjusted Tweet'].apply(demote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing all text to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowercase(text):    \n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "df['Adjusted Tweet'] = df['Adjusted Tweet'].apply(lowercase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing mentions and hashtagged words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_mentions_hashtags(text):\n",
    "    text = re.sub(\"@[A-Za-z0-9_]+\",\"\", text)\n",
    "    text = re.sub(\"#[A-Za-z0-9_]+\",\"\", text)\n",
    "    return text\n",
    "\n",
    "df['Adjusted Tweet'] = df['Adjusted Tweet'].apply(remove_mentions_hashtags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_links(text):\n",
    "    text = re.sub('http://\\S+|https://\\S+', '', text)\n",
    "    text = re.sub('http[s]?://\\S+', '', text)\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    text = re.sub(r'bit.ly/\\S+', '', text) # remove bitly links\n",
    "    text = text.strip('[link]') # remove [links]\n",
    "    return text\n",
    "\n",
    "df['Adjusted Tweet'] = df['Adjusted Tweet'].apply(remove_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing all Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def punctuation_remove(text):\n",
    "    text = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    return text\n",
    "\n",
    "df['Adjusted Tweet'] = df['Adjusted Tweet'].apply(punctuation_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "def tokenize(text):\n",
    "    text = word_tokenize(text)\n",
    "    return text\n",
    "\n",
    "df['Adjusted Tweet'] = df['Adjusted Tweet'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopword Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stop_words = stopwords.words('english')\n",
    "    text = [word for word in text if word not in stop_words]\n",
    "    return text\n",
    "\n",
    "df['Adjusted Tweet'] = df['Adjusted Tweet'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "\n",
    "def stem(text):\n",
    "    stemmed = [porter.stem(word) for word in text]\n",
    "    return text\n",
    "\n",
    "df['Adjusted Tweet'] = df['Adjusted Tweet'].apply(stem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "\n",
    "def detokenize(text):\n",
    "    TreebankWordDetokenizer().detokenize(text)\n",
    "    return text\n",
    "\n",
    "df['Adjusted Tweet'] = df['Adjusted Tweet'].apply(detokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert Polarity Score Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(loc=7,\n",
    "          column='Polarity Score',\n",
    "          value=df['Adjusted Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>user</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>raw_content</th>\n",
       "      <th>rendered_content</th>\n",
       "      <th>Adjusted Tweet</th>\n",
       "      <th>Polarity Score</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>replies</th>\n",
       "      <th>quoteCount</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>lang</th>\n",
       "      <th>media</th>\n",
       "      <th>mentionedUsers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1486661338390831105</td>\n",
       "      <td>2022-01-27 11:24:18+00:00</td>\n",
       "      <td>WorldToBe1</td>\n",
       "      <td>10769</td>\n",
       "      <td>#Russia-#Ukraine debate sparks fiery exchange ...</td>\n",
       "      <td>#Russia-#Ukraine debate sparks fiery exchange ...</td>\n",
       "      <td>[debate, sparks, fiery, exchange, 2014, backed...</td>\n",
       "      <td>[debate, sparks, fiery, exchange, 2014, backed...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['Russia', 'Ukraine', 'CNN', 'USA', 'EU', 'NAT...</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1486105614803775490</td>\n",
       "      <td>2022-01-25 22:36:03+00:00</td>\n",
       "      <td>embeegle</td>\n",
       "      <td>2246</td>\n",
       "      <td>Can you say pipeline?  A larger cut coming to ...</td>\n",
       "      <td>Can you say pipeline?  A larger cut coming to ...</td>\n",
       "      <td>[say, pipeline, larger, cut, coming, cost]</td>\n",
       "      <td>[say, pipeline, larger, cut, coming, cost]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['PutinsPuppet', 'ukrainewar']</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1486056169013661697</td>\n",
       "      <td>2022-01-25 19:19:34+00:00</td>\n",
       "      <td>Vlad_Mykhnenko</td>\n",
       "      <td>1068</td>\n",
       "      <td>Foreign exchange markets somehow are not betti...</td>\n",
       "      <td>Foreign exchange markets somehow are not betti...</td>\n",
       "      <td>[foreign, exchange, markets, somehow, betting,...</td>\n",
       "      <td>[foreign, exchange, markets, somehow, betting,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['russianinvasion', 'ukrainewar']</td>\n",
       "      <td>en</td>\n",
       "      <td>[Photo(previewUrl='https://pbs.twimg.com/media...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1486019310069989376</td>\n",
       "      <td>2022-01-25 16:53:07+00:00</td>\n",
       "      <td>RaVe_74</td>\n",
       "      <td>5309</td>\n",
       "      <td>#borisjohnson's expertise in foreign affairs -...</td>\n",
       "      <td>#borisjohnson's expertise in foreign affairs -...</td>\n",
       "      <td>[expertise, foreign, affairs, trying, managed,...</td>\n",
       "      <td>[expertise, foreign, affairs, trying, managed,...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['borisjohnson', 'freenazanin', 'BrexitShamble...</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1485989417084985347</td>\n",
       "      <td>2022-01-25 14:54:20+00:00</td>\n",
       "      <td>miamicool</td>\n",
       "      <td>1035</td>\n",
       "      <td>Seems that #ukrainewar just became that \"line ...</td>\n",
       "      <td>Seems that #ukrainewar just became that \"line ...</td>\n",
       "      <td>[seems, became, line, sand, whole, world, war,...</td>\n",
       "      <td>[seems, became, line, sand, whole, world, war,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['ukrainewar']</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                       date            user  \\\n",
       "0  1486661338390831105  2022-01-27 11:24:18+00:00      WorldToBe1   \n",
       "1  1486105614803775490  2022-01-25 22:36:03+00:00        embeegle   \n",
       "2  1486056169013661697  2022-01-25 19:19:34+00:00  Vlad_Mykhnenko   \n",
       "3  1486019310069989376  2022-01-25 16:53:07+00:00         RaVe_74   \n",
       "4  1485989417084985347  2022-01-25 14:54:20+00:00       miamicool   \n",
       "\n",
       "   user_followers                                        raw_content  \\\n",
       "0           10769  #Russia-#Ukraine debate sparks fiery exchange ...   \n",
       "1            2246  Can you say pipeline?  A larger cut coming to ...   \n",
       "2            1068  Foreign exchange markets somehow are not betti...   \n",
       "3            5309  #borisjohnson's expertise in foreign affairs -...   \n",
       "4            1035  Seems that #ukrainewar just became that \"line ...   \n",
       "\n",
       "                                    rendered_content  \\\n",
       "0  #Russia-#Ukraine debate sparks fiery exchange ...   \n",
       "1  Can you say pipeline?  A larger cut coming to ...   \n",
       "2  Foreign exchange markets somehow are not betti...   \n",
       "3  #borisjohnson's expertise in foreign affairs -...   \n",
       "4  Seems that #ukrainewar just became that \"line ...   \n",
       "\n",
       "                                      Adjusted Tweet  \\\n",
       "0  [debate, sparks, fiery, exchange, 2014, backed...   \n",
       "1         [say, pipeline, larger, cut, coming, cost]   \n",
       "2  [foreign, exchange, markets, somehow, betting,...   \n",
       "3  [expertise, foreign, affairs, trying, managed,...   \n",
       "4  [seems, became, line, sand, whole, world, war,...   \n",
       "\n",
       "                                      Polarity Score  likes  retweets  \\\n",
       "0  [debate, sparks, fiery, exchange, 2014, backed...      0         0   \n",
       "1         [say, pipeline, larger, cut, coming, cost]      1         1   \n",
       "2  [foreign, exchange, markets, somehow, betting,...      1         0   \n",
       "3  [expertise, foreign, affairs, trying, managed,...      3         1   \n",
       "4  [seems, became, line, sand, whole, world, war,...      0         0   \n",
       "\n",
       "   replies  quoteCount                                           hashtags  \\\n",
       "0        0           0  ['Russia', 'Ukraine', 'CNN', 'USA', 'EU', 'NAT...   \n",
       "1        0           0                     ['PutinsPuppet', 'ukrainewar']   \n",
       "2        0           0                  ['russianinvasion', 'ukrainewar']   \n",
       "3        0           0  ['borisjohnson', 'freenazanin', 'BrexitShamble...   \n",
       "4        0           0                                     ['ukrainewar']   \n",
       "\n",
       "  lang                                              media mentionedUsers  \n",
       "0   en                                                NaN            NaN  \n",
       "1   en                                                NaN            NaN  \n",
       "2   en  [Photo(previewUrl='https://pbs.twimg.com/media...            NaN  \n",
       "3   en                                                NaN            NaN  \n",
       "4   en                                                NaN            NaN  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment Analysis using NLTK's VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'encode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m     text \u001b[38;5;241m=\u001b[39m sia\u001b[38;5;241m.\u001b[39mpolarity_scores(text)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m text\n\u001b[0;32m----> 8\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPolarity Score\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPolarity Score\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentiment_analysis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/series.py?line=4660'>4661</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/series.py?line=4661'>4662</a>\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/series.py?line=4662'>4663</a>\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/series.py?line=4665'>4666</a>\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/series.py?line=4666'>4667</a>\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/series.py?line=4667'>4668</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/series.py?line=4668'>4669</a>\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/series.py?line=4669'>4670</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/series.py?line=4768'>4769</a>\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/series.py?line=4769'>4770</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/series.py?line=4770'>4771</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/apply.py?line=1119'>1120</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/apply.py?line=1121'>1122</a>\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/apply.py?line=1122'>1123</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/apply.py:1174\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/apply.py?line=1171'>1172</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/apply.py?line=1172'>1173</a>\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[0;32m-> <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/apply.py?line=1173'>1174</a>\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/apply.py?line=1174'>1175</a>\u001b[0m             values,\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/apply.py?line=1175'>1176</a>\u001b[0m             f,\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/apply.py?line=1176'>1177</a>\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/apply.py?line=1177'>1178</a>\u001b[0m         )\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/apply.py?line=1179'>1180</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/apply.py?line=1180'>1181</a>\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/apply.py?line=1181'>1182</a>\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/apply.py?line=1182'>1183</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/_libs/lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[33], line 5\u001b[0m, in \u001b[0;36msentiment_analysis\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msentiment_analysis\u001b[39m(text):  \n\u001b[0;32m----> 5\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[43msia\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolarity_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m text\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/nltk/sentiment/vader.py:366\u001b[0m, in \u001b[0;36mSentimentIntensityAnalyzer.polarity_scores\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/nltk/sentiment/vader.py?line=354'>355</a>\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/nltk/sentiment/vader.py?line=355'>356</a>\u001b[0m \u001b[39mReturn a float for sentiment strength based on the input text.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/nltk/sentiment/vader.py?line=356'>357</a>\u001b[0m \u001b[39mPositive values are positive valence, negative value are negative\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/nltk/sentiment/vader.py?line=362'>363</a>\u001b[0m \u001b[39m    matched as if it was a normal word in the sentence.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/nltk/sentiment/vader.py?line=363'>364</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/nltk/sentiment/vader.py?line=364'>365</a>\u001b[0m \u001b[39m# text, words_and_emoticons, is_cap_diff = self.preprocess(text)\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/nltk/sentiment/vader.py?line=365'>366</a>\u001b[0m sentitext \u001b[39m=\u001b[39m SentiText(\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/nltk/sentiment/vader.py?line=366'>367</a>\u001b[0m     text, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconstants\u001b[39m.\u001b[39;49mPUNC_LIST, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconstants\u001b[39m.\u001b[39;49mREGEX_REMOVE_PUNCTUATION\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/nltk/sentiment/vader.py?line=367'>368</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/nltk/sentiment/vader.py?line=368'>369</a>\u001b[0m sentiments \u001b[39m=\u001b[39m []\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/nltk/sentiment/vader.py?line=369'>370</a>\u001b[0m words_and_emoticons \u001b[39m=\u001b[39m sentitext\u001b[39m.\u001b[39mwords_and_emoticons\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/nltk/sentiment/vader.py:270\u001b[0m, in \u001b[0;36mSentiText.__init__\u001b[0;34m(self, text, punc_list, regex_remove_punctuation)\u001b[0m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/nltk/sentiment/vader.py?line=267'>268</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, text, punc_list, regex_remove_punctuation):\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/nltk/sentiment/vader.py?line=268'>269</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(text, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/nltk/sentiment/vader.py?line=269'>270</a>\u001b[0m         text \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(text\u001b[39m.\u001b[39;49mencode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/nltk/sentiment/vader.py?line=270'>271</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext \u001b[39m=\u001b[39m text\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/nltk/sentiment/vader.py?line=271'>272</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mPUNC_LIST \u001b[39m=\u001b[39m punc_list\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'encode'"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def sentiment_analysis(text):  \n",
    "    text = sia.polarity_scores(text)\n",
    "    return text\n",
    "\n",
    "df['Polarity Score'] = df['Polarity Score'].apply(sentiment_analysis)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
