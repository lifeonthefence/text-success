{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5d28bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3867ab2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../Data/Processed Dataset TF-IDF Train')\n",
    "test_data = pd.read_csv('../Data/Processed Dataset TF-IDF Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "415ba325",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop('time of day', axis = 1)\n",
    "train_data = train_data.drop('id', axis = 1)\n",
    "train_data = train_data.drop('date_x', axis = 1)\n",
    "train_data = train_data.drop('user', axis = 1)\n",
    "\n",
    "test_data = test_data.drop('time of day', axis = 1)\n",
    "test_data = test_data.drop('id', axis = 1)\n",
    "test_data = test_data.drop('date_x', axis = 1)\n",
    "test_data = test_data.drop('user', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e41af23",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop('rendered_content', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "110f24a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop('Adjusted Tweet', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c866c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.drop('rendered_content', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31b002e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.drop('Adjusted Tweet', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bc74c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef manual_test():\\n    \"\"\" Validate estimator using sklearn\\'s provided utility and ensure it can fit and predict on fake dataset. \"\"\"\\n    check_estimator(HurdleRegression())\\n    from sklearn.datasets import make_regression\\n    X, y = make_regression()\\n    reg = HurdleRegression()\\n    reg.fit(X, y)\\n    reg.predict(X)\\n\\n\\nif __name__ == \\'__main__\\':\\n    manual_test()\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Optional, Union\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "#from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "\n",
    "\n",
    "class HurdleRegression(BaseEstimator):\n",
    "    \"\"\" Regression model which handles excessive zeros by fitting a two-part model and combining predictions:\n",
    "            1) binary classifier\n",
    "            2) continuous regression\n",
    "    Implementeted as a valid sklearn estimator, so it can be used in pipelines and GridSearch objects.\n",
    "    Args:\n",
    "        clf_name: currently supports either 'logistic' or 'LGBMClassifier'\n",
    "        reg_name: currently supports either 'linear' or 'LGBMRegressor'\n",
    "        clf_params: dict of parameters to pass to classifier sub-model when initialized\n",
    "        reg_params: dict of parameters to pass to regression sub-model when initialized\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 clf_name: str = 'logistic',\n",
    "                 reg_name: str = 'linear',\n",
    "                 clf_params: Optional[dict] = None,\n",
    "                 reg_params: Optional[dict] = None):\n",
    "\n",
    "        self.clf_name = clf_name\n",
    "        self.reg_name = reg_name\n",
    "        self.clf_params = clf_params\n",
    "        self.reg_params = reg_params\n",
    "\n",
    "    @staticmethod\n",
    "    def _resolve_estimator(func_name: str):\n",
    "        \"\"\" Lookup table for supported estimators.\n",
    "        This is necessary because sklearn estimator default arguments\n",
    "        must pass equality test, and instantiated sub-estimators are not equal. \"\"\"\n",
    "\n",
    "        funcs = {'linear': LinearRegression(),\n",
    "                 'logistic': LogisticRegression(solver='liblinear'),\n",
    "                 #'LGBMRegressor': LGBMRegressor(n_estimators=50),\n",
    "                 #'LGBMClassifier': LGBMClassifier(n_estimators=50)\n",
    "                }\n",
    "\n",
    "        return funcs[func_name]\n",
    "\n",
    "    def fit(self,\n",
    "            X: Union[np.ndarray, pd.DataFrame],\n",
    "            y: Union[np.ndarray, pd.Series]):\n",
    "        X, y = check_X_y(X, y, dtype=None,\n",
    "                         accept_sparse=False,\n",
    "                         accept_large_sparse=False,\n",
    "                         force_all_finite='allow-nan')\n",
    "\n",
    "        if X.shape[1] < 2:\n",
    "            raise ValueError('Cannot fit model when n_features = 1')\n",
    "\n",
    "        self.clf_ = self._resolve_estimator(self.clf_name)\n",
    "        if self.clf_params:\n",
    "            self.clf_.set_params(**self.clf_params)\n",
    "        self.clf_.fit(X, y > 0)\n",
    "\n",
    "        self.reg_ = self._resolve_estimator(self.reg_name)\n",
    "        if self.reg_params:\n",
    "            self.reg_.set_params(**self.reg_params)\n",
    "        self.reg_.fit(X[y > 0], y[y > 0])\n",
    "\n",
    "        self.is_fitted_ = True\n",
    "        return self\n",
    "\n",
    "    def predict(self, X: Union[np.ndarray, pd.DataFrame]):\n",
    "        \"\"\" Predict combined response using binary classification outcome \"\"\"\n",
    "        X = check_array(X, accept_sparse=False, accept_large_sparse=False)\n",
    "        check_is_fitted(self, 'is_fitted_')\n",
    "        return self.clf_.predict(X) * self.reg_.predict(X)\n",
    "\n",
    "    def predict_expected_value(self, X: Union[np.ndarray, pd.DataFrame]):\n",
    "        \"\"\" Predict combined response using probabilistic classification outcome \"\"\"\n",
    "        X = check_array(X, accept_sparse=False, accept_large_sparse=False)\n",
    "        check_is_fitted(self, 'is_fitted_')\n",
    "        return self.clf_.predict_proba(X)[:, 1] * self.reg_.predict(X)\n",
    "\n",
    "'''\n",
    "def manual_test():\n",
    "    \"\"\" Validate estimator using sklearn's provided utility and ensure it can fit and predict on fake dataset. \"\"\"\n",
    "    check_estimator(HurdleRegression())\n",
    "    from sklearn.datasets import make_regression\n",
    "    X, y = make_regression()\n",
    "    reg = HurdleRegression()\n",
    "    reg.fit(X, y)\n",
    "    reg.predict(X)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    manual_test()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df9ee6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 15.532999069422997\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "\n",
    "\n",
    "# split data into features and target\n",
    "X_train = train_data.drop(columns=['retweets'])\n",
    "y_train = train_data['retweets']\n",
    "X_test = test_data.drop(columns=['retweets'])\n",
    "y_test = test_data['retweets']\n",
    "\n",
    "# initialize HurdleRegression model\n",
    "clf_name = 'logistic'\n",
    "reg_name = 'linear'\n",
    "\n",
    "model = HurdleRegression(clf_name=clf_name, reg_name=reg_name)\n",
    "\n",
    "# fit model on training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# evaluate predictions using root mean squared error\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38bf478",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
