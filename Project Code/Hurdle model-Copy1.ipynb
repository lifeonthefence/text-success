{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa765af5",
   "metadata": {},
   "source": [
    "# Dataset adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84be600a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1781b5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing the datasets as pandas dataframes\n",
    "\n",
    "train_data = pd.read_csv('../Data/Processed Dataset TF-IDF Train')\n",
    "test_data = pd.read_csv('../Data/Processed Dataset TF-IDF Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6cc5ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing unnecessary columns\n",
    "\n",
    "train_data = train_data.drop('time of day', axis = 1)\n",
    "train_data = train_data.drop('id', axis = 1)\n",
    "train_data = train_data.drop('date_x', axis = 1)\n",
    "train_data = train_data.drop('user', axis = 1)\n",
    "\n",
    "test_data = test_data.drop('time of day', axis = 1)\n",
    "test_data = test_data.drop('id', axis = 1)\n",
    "test_data = test_data.drop('date_x', axis = 1)\n",
    "test_data = test_data.drop('user', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f943ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop('rendered_content', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d9b3043",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop('Adjusted Tweet', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7370a12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.drop('rendered_content', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa2ff219",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.drop('Adjusted Tweet', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f1b0d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour of tweet</th>\n",
       "      <th>Early Morning Count</th>\n",
       "      <th>Morning Count</th>\n",
       "      <th>Noon Count</th>\n",
       "      <th>Eve Count</th>\n",
       "      <th>Night Count</th>\n",
       "      <th>Late Night Count</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>Months Since Creation of Account</th>\n",
       "      <th>Negative Score</th>\n",
       "      <th>...</th>\n",
       "      <th>youre</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yr</th>\n",
       "      <th>zaporizhzhia</th>\n",
       "      <th>zaporozhye</th>\n",
       "      <th>zelenskiy</th>\n",
       "      <th>zelensky</th>\n",
       "      <th>zelenskys</th>\n",
       "      <th>zelenskyy</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>795</td>\n",
       "      <td>145</td>\n",
       "      <td>0.077</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2506</td>\n",
       "      <td>81</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2659</td>\n",
       "      <td>167</td>\n",
       "      <td>0.107</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>394</td>\n",
       "      <td>10</td>\n",
       "      <td>0.081</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46284</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>161</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46285</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7078</td>\n",
       "      <td>92</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46286</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3554</td>\n",
       "      <td>145</td>\n",
       "      <td>0.184</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46287</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46288</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>762</td>\n",
       "      <td>34</td>\n",
       "      <td>0.316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46289 rows Ã— 2142 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       hour of tweet  Early Morning Count  Morning Count  Noon Count  \\\n",
       "0                 23                    0              0           0   \n",
       "1                 23                    0              0           0   \n",
       "2                 23                    0              0           0   \n",
       "3                 23                    0              0           0   \n",
       "4                 22                    0              0           0   \n",
       "...              ...                  ...            ...         ...   \n",
       "46284             23                    0              0           0   \n",
       "46285             23                    0              0           0   \n",
       "46286             22                    0              0           0   \n",
       "46287             12                    0              0           1   \n",
       "46288             22                    0              0           0   \n",
       "\n",
       "       Eve Count  Night Count  Late Night Count  user_followers  \\\n",
       "0              0            1                 0             795   \n",
       "1              0            1                 0            2506   \n",
       "2              0            1                 0            2659   \n",
       "3              0            1                 0             394   \n",
       "4              0            1                 0             113   \n",
       "...          ...          ...               ...             ...   \n",
       "46284          0            1                 0             200   \n",
       "46285          0            1                 0            7078   \n",
       "46286          0            1                 0            3554   \n",
       "46287          0            0                 0             190   \n",
       "46288          0            1                 0             762   \n",
       "\n",
       "       Months Since Creation of Account  Negative Score  ...  youre  youtube  \\\n",
       "0                                   145           0.077  ...    0.0      0.0   \n",
       "1                                    81           0.000  ...    0.0      0.0   \n",
       "2                                   167           0.107  ...    0.0      0.0   \n",
       "3                                    10           0.081  ...    0.0      0.0   \n",
       "4                                   113           0.000  ...    0.0      0.0   \n",
       "...                                 ...             ...  ...    ...      ...   \n",
       "46284                               161           0.000  ...    0.0      0.0   \n",
       "46285                                92           0.000  ...    0.0      0.0   \n",
       "46286                               145           0.184  ...    0.0      0.0   \n",
       "46287                                 6           0.000  ...    0.0      0.0   \n",
       "46288                                34           0.316  ...    0.0      0.0   \n",
       "\n",
       "        yr  zaporizhzhia  zaporozhye  zelenskiy  zelensky  zelenskys  \\\n",
       "0      0.0           0.0         0.0        0.0       0.0        0.0   \n",
       "1      0.0           0.0         0.0        0.0       0.0        0.0   \n",
       "2      0.0           0.0         0.0        0.0       0.0        0.0   \n",
       "3      0.0           0.0         0.0        0.0       0.0        0.0   \n",
       "4      0.0           0.0         0.0        0.0       0.0        0.0   \n",
       "...    ...           ...         ...        ...       ...        ...   \n",
       "46284  0.0           0.0         0.0        0.0       0.0        0.0   \n",
       "46285  0.0           0.0         0.0        0.0       0.0        0.0   \n",
       "46286  0.0           0.0         0.0        0.0       0.0        0.0   \n",
       "46287  0.0           0.0         0.0        0.0       0.0        0.0   \n",
       "46288  0.0           0.0         0.0        0.0       0.0        0.0   \n",
       "\n",
       "       zelenskyy  zone  \n",
       "0            0.0   0.0  \n",
       "1            0.0   0.0  \n",
       "2            0.0   0.0  \n",
       "3            0.0   0.0  \n",
       "4            0.0   0.0  \n",
       "...          ...   ...  \n",
       "46284        0.0   0.0  \n",
       "46285        0.0   0.0  \n",
       "46286        0.0   0.0  \n",
       "46287        0.0   0.0  \n",
       "46288        0.0   0.0  \n",
       "\n",
       "[46289 rows x 2142 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c52d4da5",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (391950818.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [12]\u001b[1;36m\u001b[0m\n\u001b[1;33m    pip install lightgbm\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#installing classification and regresion model library \n",
    "pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d470e895",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier, LGBMRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6cb968",
   "metadata": {},
   "source": [
    "# Hurdle Regression class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "59765868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef manual_test():\\n    \"\"\" Validate estimator using sklearn\\'s provided utility and ensure it can fit and predict on fake dataset. \"\"\"\\n    check_estimator(HurdleRegression())\\n    from sklearn.datasets import make_regression\\n    X, y = make_regression()\\n    reg = HurdleRegression()\\n    reg.fit(X, y)\\n    reg.predict(X)\\n\\n\\nif __name__ == \\'__main__\\':\\n    manual_test()\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Optional, Union\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "\n",
    "class HurdleRegression(BaseEstimator):\n",
    "    \"\"\" Regression model which handles excessive zeros by fitting a two-part model and combining predictions:\n",
    "            1) binary classifier\n",
    "            2) continuous regression\n",
    "    Implementeted as a valid sklearn estimator, so it can be used in pipelines and GridSearch objects.\n",
    "    Args:\n",
    "        clf_name: currently supports either 'logistic' or 'LGBMClassifier'\n",
    "        reg_name: currently supports either 'linear' or 'LGBMRegressor'\n",
    "        clf_params: dict of parameters to pass to classifier sub-model when initialized\n",
    "        reg_params: dict of parameters to pass to regression sub-model when initialized\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 clf_name: str = 'logistic', \n",
    "                 reg_name: str = 'linear',\n",
    "                 clf_params: Optional[dict] = None,\n",
    "                 reg_params: Optional[dict] = None):\n",
    "\n",
    "        self.clf_name = clf_name\n",
    "        self.reg_name = reg_name\n",
    "        self.clf_params = clf_params\n",
    "        self.reg_params = reg_params\n",
    "\n",
    "    @staticmethod\n",
    "    def _resolve_estimator(func_name: str):\n",
    "        \"\"\" Lookup table for supported estimators.\n",
    "        This is necessary because sklearn estimator default arguments\n",
    "        must pass equality test, and instantiated sub-estimators are not equal. \"\"\"\n",
    "\n",
    "        funcs = {'linear': LinearRegression(),\n",
    "                 'logistic': LogisticRegression(solver='liblinear'),\n",
    "                 'LGBMRegressor': LGBMRegressor(n_estimators=50),\n",
    "                 'LGBMClassifier': LGBMClassifier(n_estimators=50), \n",
    "                 'DTClassifier' : DecisionTreeClassifier(), \n",
    "                 'DTRegressor' : DecisionTreeRegressor(), \n",
    "                 'RFClassifier' :RandomForestClassifier(), \n",
    "                 'RFRegressor' : RandomForestRegressor(),\n",
    "                 'GBClassifier' : GradientBoostingClassifier(), \n",
    "                 'GBRegressor' : GradientBoostingRegressor(), \n",
    "                }\n",
    "\n",
    "        return funcs[func_name]\n",
    "\n",
    "    def fit(self,\n",
    "            X: Union[np.ndarray, pd.DataFrame],\n",
    "            y: Union[np.ndarray, pd.Series]):\n",
    "        X, y = check_X_y(X, y, dtype=None,\n",
    "                         accept_sparse=False,\n",
    "                         accept_large_sparse=False,\n",
    "                         force_all_finite='allow-nan')\n",
    "\n",
    "        if X.shape[1] < 2:\n",
    "            raise ValueError('Cannot fit model when n_features = 1')\n",
    "\n",
    "        self.clf_ = self._resolve_estimator(self.clf_name)\n",
    "        if self.clf_params:\n",
    "            self.clf_.set_params(**self.clf_params)\n",
    "        self.clf_.fit(X, y > 0)\n",
    "\n",
    "        self.reg_ = self._resolve_estimator(self.reg_name)\n",
    "        if self.reg_params:\n",
    "            self.reg_.set_params(**self.reg_params)\n",
    "        self.reg_.fit(X[y > 0], y[y > 0])\n",
    "\n",
    "        self.is_fitted_ = True\n",
    "        return self\n",
    "\n",
    "    def predict(self, X: Union[np.ndarray, pd.DataFrame]):\n",
    "        \"\"\" Predict combined response using binary classification outcome \"\"\"\n",
    "        X = check_array(X, accept_sparse=False, accept_large_sparse=False)\n",
    "        check_is_fitted(self, 'is_fitted_')\n",
    "        return self.clf_.predict(X) * self.reg_.predict(X)\n",
    "\n",
    "    def predict_expected_value(self, X: Union[np.ndarray, pd.DataFrame]):\n",
    "        \"\"\" Predict combined response using probabilistic classification outcome \"\"\"\n",
    "        X = check_array(X, accept_sparse=False, accept_large_sparse=False)\n",
    "        check_is_fitted(self, 'is_fitted_')\n",
    "        return self.clf_.predict_proba(X)[:, 1] * self.reg_.predict(X)\n",
    "\n",
    "'''\n",
    "def manual_test():\n",
    "    \"\"\" Validate estimator using sklearn's provided utility and ensure it can fit and predict on fake dataset. \"\"\"\n",
    "    check_estimator(HurdleRegression())\n",
    "    from sklearn.datasets import make_regression\n",
    "    X, y = make_regression()\n",
    "    reg = HurdleRegression()\n",
    "    reg.fit(X, y)\n",
    "    reg.predict(X)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    manual_test()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44101b7c",
   "metadata": {},
   "source": [
    "# Classifier: Logistic regression, Regressor: Linear Regression\n",
    "<b> The following models implement these 3 aspects in the following order\n",
    "- Model creation\n",
    "- Cross validation \n",
    "- Accuracy for 0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0dc328f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 30475.535875067104\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "# split data into features and target\n",
    "X_train = train_data.drop(columns=['retweets'])\n",
    "y_train = train_data['retweets']\n",
    "X_test = test_data.drop(columns=['retweets'])\n",
    "y_test = test_data['retweets']\n",
    "\n",
    "# initialize HurdleRegression model\n",
    "clf_name = 'logistic'\n",
    "reg_name = 'linear'\n",
    "\n",
    "model = HurdleRegression(clf_name=clf_name, reg_name=reg_name)\n",
    "\n",
    "# fit model on training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# evaluate predictions using root mean squared error\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b240801b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting a list of all the predictions \n",
    "preds = model.predict_expected_value(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e40e0fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.33154249 0.73193691 2.22962226 ... 0.15154977 6.88250507 0.11577636]\n"
     ]
    }
   ],
   "source": [
    "print(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03c74e7",
   "metadata": {},
   "source": [
    "Cross validation for the first instance of the Hurdle model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1302b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "\n",
    "# define the scorer\n",
    "scorer = make_scorer(mean_squared_error, squared=False)\n",
    "\n",
    "# cross-validate the model using the scorer\n",
    "scores = cross_val_score(model, X_train, y_train, cv=5, scoring=scorer)\n",
    "\n",
    "# print the average RMSE and its standard deviation\n",
    "print('Scores:', scores)\n",
    "print(\"Average RMSE:\", scores.mean())\n",
    "print(\"Standard deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4d8a6c",
   "metadata": {},
   "source": [
    "Accuracy for zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4780ffbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking at the 0-1 accuracy\n",
    "preds = model.predict_expected_value(X_test)\n",
    "preds_int = pd.Series(preds.round().astype(int)).to_numpy()\n",
    "sum(preds_int == y_test.to_numpy())/len(preds_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7b27cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(np.multiply((preds_int == y_test.to_numpy()), y_test.to_numpy() == 0))/sum(y_test.to_numpy() == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d022b772",
   "metadata": {},
   "source": [
    "#can use lasso penalty for logistic regresion hyperparameter tuning \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e366525b",
   "metadata": {},
   "source": [
    "# Classifier: LGBM, Regressor: LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8d425b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 29.172875901019193\n"
     ]
    }
   ],
   "source": [
    "#try boosted tree as a regressor \n",
    "\n",
    "# initialize HurdleRegression model\n",
    "clf_name = 'LGBMClassifier'\n",
    "reg_name = 'LGBMRegressor'\n",
    "\n",
    "model_2 = HurdleRegression(clf_name=clf_name, reg_name=reg_name)\n",
    "\n",
    "# fit model on training data\n",
    "model_2.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on test data\n",
    "y_pred = model_2.predict(X_test)\n",
    "\n",
    "# evaluate predictions using root mean squared error\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3147c607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5741812840231574"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Looking at the 0-1 accuracy\n",
    "preds_2 = model_2.predict_expected_value(X_test)\n",
    "preds_2_int = pd.Series(preds_2.round().astype(int)).to_numpy()\n",
    "sum(preds_2_int == y_test.to_numpy())/len(preds_2_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "690265a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7834258863733448"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.multiply((preds_2_int == y_test.to_numpy()), y_test.to_numpy() == 0))/sum(y_test.to_numpy() == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4ea3b4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [12.36066237 14.74897737 14.49042077 20.0200894  11.65086527]\n",
      "Average RMSE: 14.654203038080755\n",
      "Standard deviation: 2.9362871050708796\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "\n",
    "# define the scorer\n",
    "scorer = make_scorer(mean_squared_error, squared=False)\n",
    "\n",
    "# cross-validate the model using the scorer\n",
    "scores_2 = cross_val_score(model_2, X_train, y_train, cv=5, scoring=scorer)\n",
    "\n",
    "# print the average RMSE and its standard deviation\n",
    "print('Scores:', scores_2)\n",
    "print(\"Average RMSE:\", scores_2.mean())\n",
    "print(\"Standard deviation:\", scores_2.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31a6db1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting shap\n",
      "  Downloading shap-0.41.0-cp39-cp39-win_amd64.whl (435 kB)\n",
      "     -------------------------------------- 435.6/435.6 kB 5.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\ekmho\\anaconda3\\lib\\site-packages (from shap) (1.21.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\ekmho\\anaconda3\\lib\\site-packages (from shap) (1.4.4)\n",
      "Requirement already satisfied: tqdm>4.25.0 in c:\\users\\ekmho\\anaconda3\\lib\\site-packages (from shap) (4.64.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\ekmho\\anaconda3\\lib\\site-packages (from shap) (1.10.1)\n",
      "Requirement already satisfied: packaging>20.9 in c:\\users\\ekmho\\anaconda3\\lib\\site-packages (from shap) (21.3)\n",
      "Collecting slicer==0.0.7\n",
      "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\ekmho\\anaconda3\\lib\\site-packages (from shap) (2.0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\ekmho\\anaconda3\\lib\\site-packages (from shap) (1.1.1)\n",
      "Requirement already satisfied: numba in c:\\users\\ekmho\\anaconda3\\lib\\site-packages (from shap) (0.55.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\ekmho\\anaconda3\\lib\\site-packages (from packaging>20.9->shap) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\ekmho\\anaconda3\\lib\\site-packages (from tqdm>4.25.0->shap) (0.4.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ekmho\\anaconda3\\lib\\site-packages (from numba->shap) (63.4.1)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in c:\\users\\ekmho\\anaconda3\\lib\\site-packages (from numba->shap) (0.38.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\ekmho\\anaconda3\\lib\\site-packages (from pandas->shap) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ekmho\\anaconda3\\lib\\site-packages (from pandas->shap) (2022.1)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\ekmho\\anaconda3\\lib\\site-packages (from scikit-learn->shap) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ekmho\\anaconda3\\lib\\site-packages (from scikit-learn->shap) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ekmho\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->shap) (1.16.0)\n",
      "Installing collected packages: slicer, shap\n",
      "Successfully installed shap-0.41.0 slicer-0.0.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c373ae21",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidModelError",
     "evalue": "Model type not yet supported by TreeExplainer: <class '__main__.HurdleRegression'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidModelError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshap\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m explainer \u001b[38;5;241m=\u001b[39m \u001b[43mshap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTreeExplainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m shap_values \u001b[38;5;241m=\u001b[39m explainer\u001b[38;5;241m.\u001b[39mshap_values(X_test)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\shap\\explainers\\_tree.py:149\u001b[0m, in \u001b[0;36mTree.__init__\u001b[1;34m(self, model, data, model_output, feature_perturbation, feature_names, approximate, **deprecated_options)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_perturbation \u001b[38;5;241m=\u001b[39m feature_perturbation\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpected_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 149\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mTreeEnsemble\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_missing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_output \u001b[38;5;241m=\u001b[39m model_output\n\u001b[0;32m    151\u001b[0m \u001b[38;5;66;03m#self.model_output = self.model.model_output # this allows the TreeEnsemble to translate model outputs types by how it loads the model\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\shap\\explainers\\_tree.py:993\u001b[0m, in \u001b[0;36mTreeEnsemble.__init__\u001b[1;34m(self, model, data, data_missing, model_output)\u001b[0m\n\u001b[0;32m    991\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_offset \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39minit_params[param_idx]\n\u001b[0;32m    992\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 993\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidModelError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type not yet supported by TreeExplainer: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mtype\u001b[39m(model)))\n\u001b[0;32m    995\u001b[0m \u001b[38;5;66;03m# build a dense numpy version of all the tree objects\u001b[39;00m\n\u001b[0;32m    996\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrees \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrees:\n",
      "\u001b[1;31mInvalidModelError\u001b[0m: Model type not yet supported by TreeExplainer: <class '__main__.HurdleRegression'>"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "explainer = shap.TreeExplainer(model_2)\n",
    "shap_values = explainer.shap_values(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437ebd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#can try boosted tree for classification as well \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89651b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to use shap to \n",
    "#can make it a multi classification model - predict into retweet number groups "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c391bc",
   "metadata": {},
   "source": [
    "# Decision trees for classifiers and regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8404cc4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 30.428483538195728\n"
     ]
    }
   ],
   "source": [
    "# initialize HurdleRegression model\n",
    "clf_name = 'DTClassifier'\n",
    "reg_name = 'DTRegressor'\n",
    "\n",
    "model_3 = HurdleRegression(clf_name=clf_name, reg_name=reg_name)\n",
    "\n",
    "# fit model on training data\n",
    "model_3.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on test data\n",
    "y_pred = model_3.predict(X_test)\n",
    "\n",
    "# evaluate predictions using root mean squared error\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d5440d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [15.97209252 22.26093198 17.33156294 20.08344546 17.38698044]\n",
      "Average RMSE: 18.607002668606015\n",
      "Standard deviation: 2.2622570565544335\n"
     ]
    }
   ],
   "source": [
    "# cross-validate the model using the scorer\n",
    "scores_3 = cross_val_score(model_3, X_train, y_train, cv=5, scoring=scorer)\n",
    "\n",
    "# print the average RMSE and its standard deviation\n",
    "print('Scores:', scores_3)\n",
    "print(\"Average RMSE:\", scores_3.mean())\n",
    "print(\"Standard deviation:\", scores_3.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0db3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking at the 0-1 accuracy\n",
    "preds_3 = model_3.predict_expected_value(X_test)\n",
    "preds_3_int = pd.Series(preds_3.round().astype(int)).to_numpy()\n",
    "sum(preds_3_int == y_test.to_numpy())/len(preds_3_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f531f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(np.multiply((preds_3_int == y_test.to_numpy()), y_test.to_numpy() == 0))/sum(y_test.to_numpy() == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b34f25e",
   "metadata": {},
   "source": [
    "# Random forests for classifiers and regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7d597794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 26.87993552144905\n"
     ]
    }
   ],
   "source": [
    "# initialize HurdleRegression model\n",
    "clf_name = 'RFClassifier'\n",
    "reg_name = 'RFRegressor'\n",
    "\n",
    "model_4 = HurdleRegression(clf_name=clf_name, reg_name=reg_name)\n",
    "\n",
    "# fit model on training data\n",
    "model_4.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on test data\n",
    "y_pred = model_4.predict(X_test)\n",
    "\n",
    "# evaluate predictions using root mean squared error\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452a73cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-validate the model using the scorer\n",
    "scores_4 = cross_val_score(model_4, X_train, y_train, cv=5, scoring=scorer)\n",
    "\n",
    "# print the average RMSE and its standard deviation\n",
    "print('Scores:', scores_4)\n",
    "print(\"Average RMSE:\", scores_4.mean())\n",
    "print(\"Standard deviation:\", scores_4.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bb587d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking at the 0-1 accuracy\n",
    "preds_4 = model_3.predict_expected_value(X_test)\n",
    "preds_4_int = pd.Series(preds_4.round().astype(int)).to_numpy()\n",
    "sum(preds_4_int == y_test.to_numpy())/len(preds_4_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a472d322",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(np.multiply((preds_4_int == y_test.to_numpy()), y_test.to_numpy() == 0))/sum(y_test.to_numpy() == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de63cda",
   "metadata": {},
   "source": [
    "# Gradient boosting for classifiers and regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9ede3e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 25.734126093120445\n"
     ]
    }
   ],
   "source": [
    "# initialize HurdleRegression model\n",
    "clf_name = 'GBClassifier'\n",
    "reg_name = 'GBRegressor'\n",
    "\n",
    "model_5 = HurdleRegression(clf_name=clf_name, reg_name=reg_name)\n",
    "\n",
    "# fit model on training data\n",
    "model_5.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on test data\n",
    "y_pred = model_5.predict(X_test)\n",
    "\n",
    "# evaluate predictions using root mean squared error\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855801cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-validate the model using the scorer\n",
    "scores_5 = cross_val_score(model_5, X_train, y_train, cv=5, scoring=scorer)\n",
    "\n",
    "# print the average RMSE and its standard deviation\n",
    "print('Scores:', scores_5)\n",
    "print(\"Average RMSE:\", scores_5.mean())\n",
    "print(\"Standard deviation:\", scores_5.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ebb0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking at the 0-1 accuracy\n",
    "preds_5 = model_3.predict_expected_value(X_test)\n",
    "preds_5_int = pd.Series(preds_5.round().astype(int)).to_numpy()\n",
    "sum(preds_5_int == y_test.to_numpy())/len(preds_5_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1034cbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(np.multiply((preds_4_int == y_test.to_numpy()), y_test.to_numpy() == 0))/sum(y_test.to_numpy() == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c325c859",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
